{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Copy of LS DS 111 - A First Look at Data.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/mowgli28/DS-Sprint-01-Dealing-With-Data/blob/master/Copy_of_LS_DS_111_A_First_Look_at_Data.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "metadata": {
        "id": "Okfr_uhwhS1X",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Lambda School Data Science - A First Look at Data\n",
        "\n"
      ]
    },
    {
      "metadata": {
        "id": "9dtJETFRhnOG",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Lecture - let's explore Python DS libraries and examples!\n",
        "\n",
        "The Python Data Science ecosystem is huge. You've seen some of the big pieces - pandas, scikit-learn, matplotlib. What parts do you want to see more of?"
      ]
    },
    {
      "metadata": {
        "id": "WiBkgmPJhmhE",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# TODO - we'll be doing this live, taking requests\n",
        "# and reproducing what it is to look up and learn things"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Jz03OG5pDxnp",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "ZacQuary Lincoln"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "lOqaPds9huME",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Assignment - now it's your turn\n",
        "\n",
        "Pick at least one Python DS library, and using documentation/examples reproduce in this notebook something cool. It's OK if you don't fully understand it or get it 100% working, but do put in effort and look things up."
      ]
    },
    {
      "metadata": {
        "id": "TGUS79cOhPWj",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import requests\n",
        "from bs4 import BeautifulSoup\n",
        "\n",
        "def loser_spider(max_pages): #defining function of webcrawler (only needs to crawl 1 page)\n",
        "    page = 1\n",
        "    \n",
        "    while page < max_pages\n",
        "        url = 'https://finance.yahoo.com/losers' \n",
        "        source_code = requests.get(url) #request info from website\n",
        "        plain_text = source_code.text   #extract raw data\n",
        "        soup = BeautifulSoup(plain_text) #put raw data into \"soup\""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "1TRmQz5y2Wtt",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# I am attempting to create a webcrawler that will scrape yahoo finance for daily losers for Billion dollar companies. I want them to be stored and tracked. Initially\n",
        "# this will just be to gather data and test a theory... I haven't fully got it down what I am attempting to do. This is just the basic outline of what I have learned\n",
        "# through watching tutorials on youtube. After I gather the data, I need to track the data and see how long it takes to increase by 10%, I also need to see how often \n",
        "# the stock choices that were chosen decline by an additional 25% & 50%, this is to hedge losses. The data I want to monitor will only be for stocks which had a daily \n",
        "# loss of 20% or higher. \n",
        "# The most interesting thing that I am learning is that the thing in which I find the most difficult, which would be checking this daily, can be automated for me \n",
        "# I'm not sure if what I am trying to accomplish is actually getting done here or not. \n",
        "# Right now the strategy that I am utilizing is for long term, safe & secure holds, however, it would be interesting to see if what I am doing for the long holds\n",
        "# can be accomplished on short term plays as well. \n",
        "# Also if I had more time I could brainstorm on strategies to use different algorithms for puts/calls or \"options\" and learn the for exchange markets to find strategies\n",
        "# used."
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "BT9gdS7viJZa",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Assignment questions\n",
        "\n",
        "After you've worked on some code, answer the following questions in this text block:\n",
        "\n",
        "1.  Describe in a paragraph of text what you did and why, as if you were writing an email to somebody interested but nontechnical.\n",
        "\n",
        "2.  What was the most challenging part of what you did?\n",
        "\n",
        "3.  What was the most interesting thing you learned?\n",
        "\n",
        "4.  What area would you like to explore with more time?\n",
        "\n",
        "\n"
      ]
    },
    {
      "metadata": {
        "id": "_XXg2crAipwP",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Stretch goals and resources\n",
        "\n",
        "Following are *optional* things for you to take a look at. Focus on the above assignment first, and make sure to commit and push your changes to GitHub (and since this is the first assignment of the sprint, open a PR as well).\n",
        "\n",
        "- [pandas documentation](https://pandas.pydata.org/pandas-docs/stable/)\n",
        "- [scikit-learn documentation](http://scikit-learn.org/stable/documentation.html)\n",
        "- [matplotlib documentation](https://matplotlib.org/contents.html)\n",
        "- [Awesome Data Science](https://github.com/bulutyazilim/awesome-datascience) - a list of many types of DS resources\n",
        "\n",
        "Stretch goals:\n",
        "\n",
        "- Find and read blogs, walkthroughs, and other examples of people working through cool things with data science - and share with your classmates!\n",
        "- Write a blog post (Medium is a popular place to publish) introducing yourself as somebody learning data science, and talking about what you've learned already and what you're excited to learn more about"
      ]
    }
  ]
}