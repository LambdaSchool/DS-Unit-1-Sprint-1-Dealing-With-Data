{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Andrea Christelle -  LS_DS_111_A_First_Look_at_Data.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/supai-red/DS-Unit-1-Sprint-1-Dealing-With-Data/blob/master/Andrea_Christelle_LS_DS_111_A_First_Look_at_Data.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Okfr_uhwhS1X",
        "colab_type": "text"
      },
      "source": [
        "# Lambda School Data Science - A First Look at Data\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9dtJETFRhnOG",
        "colab_type": "text"
      },
      "source": [
        "## Lecture - let's explore Python DS libraries and examples!\n",
        "\n",
        "The Python Data Science ecosystem is huge. You've seen some of the big pieces - pandas, scikit-learn, matplotlib. What parts do you want to see more of?"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WiBkgmPJhmhE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# TODO - we'll be doing this live, taking requests\n",
        "# and reproducing what it is to look up and learn things"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lOqaPds9huME",
        "colab_type": "text"
      },
      "source": [
        "## Assignment - now it's your turn\n",
        "\n",
        "Pick at least one Python DS library, and using documentation/examples reproduce in this notebook something cool. It's OK if you don't fully understand it or get it 100% working, but do put in effort and look things up."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TGUS79cOhPWj",
        "colab_type": "code",
        "outputId": "b54054f4-d5b0-46af-faee-1f59f6e93296",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 235
        }
      },
      "source": [
        "#TODO\n",
        "\n",
        "from bs4 import BeautifulSoup\n",
        "# changed original from urllib 2 to urllib \n",
        "import urllib\n",
        "'''Changed because original url pull language was from Python2\n",
        "but cannot seem to find new language from Python 3(yet)'''\n",
        "import urllib.request\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-11-553050af4f7e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;31m#first pull search page\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m \u001b[0mpage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0murllib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0murl\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m \u001b[0msoup\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mBeautifulSoup\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mTypeError\u001b[0m: 'module' object is not callable"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7wShvLtOcMFf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "## MY COMMENT copying my own url\n",
        "url = \"https://plato.stanford.edu\"\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Fd8joSm0cQj6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#first pull search page\n",
        "page = urllib.request(url)\n",
        "soup = BeautifulSoup(page.read())\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TkcJM7dwcT9Z",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Look at the links (peeked at the HTML)\n",
        "links = soupfindALL('a',{'class':'stitle'})\n",
        "links[:2]\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J6663Q_jcWch",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#See what the links look like\n",
        "links[0]['href']\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WedwykVicZaV",
        "colab_type": "code",
        "outputId": "974c09dc-19cf-4fe2-d5e4-8074d5b2c343",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 183
        }
      },
      "source": [
        "#from the full urls form the links\n",
        "urls = [\"https://www.plato.stanford.edu\" + link['href'] for link in links]\n",
        "urls[:10]"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-15-021046389cb2>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0murls\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m\"https://www.plato.stanford.edu\"\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mlink\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'href'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mlink\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mlinks\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0murls\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'links' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8qWkE5rkcdQI",
        "colab_type": "code",
        "outputId": "9036172a-a68b-47dc-a273-abd136660687",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 131
        }
      },
      "source": [
        "#Looks fin. Now try it by paginating across\n",
        "all_urls = []\n",
        "#note: range(x,y) is inclusive of the first number, exclusive of the seconf number\n",
        "#so range(1,3) will include 1 and 2 but not 3\n",
        "for i in range(1,26):\n",
        "  print(\"Page \" + str(i) + \", up to \" + str(len(all_urls))\n",
        "        #copied and not sure what this means  \"?&srt=l&lan=1&r=10&p=\"\n",
        "        url = \"https://plto.stanford.edu/?&srt=l&lan=1&r=10&p=\" + str(i)\n",
        "        page = urllib2.urlopen(url)\n",
        "        soup = BeautifulSoup(page.read())\n",
        "        links = soup.findALL('a', {class':'stitle'})\n",
        "        urls = [\"https://www.fanfiction.net\" + link['href'] for link in links]\n",
        "       #to add an array's elements to another array, use .extend instead of .append\n",
        "        all_urls.extend(urls)\n",
        "len(all_urls)                                     \n",
        "                            "
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "error",
          "ename": "SyntaxError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-14-a42b1405fb05>\"\u001b[0;36m, line \u001b[0;32m7\u001b[0m\n\u001b[0;31m    url = \"https://plto.stanford.edu/?&srt=l&lan=1&r=10&p=\" + str(i)\u001b[0m\n\u001b[0m      ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "71FAh7hbeMMc",
        "colab_type": "code",
        "outputId": "8e107cdf-d619-42f7-de4a-a19c913f2517",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 200
        }
      },
      "source": [
        "#Now let's take a look at a single page\n",
        "url = all_urls[0]\n",
        "page = urllib2.urlopen(url)\n",
        "soup = BeautifulSoup(page.read())"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-13-8034bd6008ef>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0murl\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mall_urls\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mpage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0murllib2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0murlopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0murl\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0msoup\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mBeautifulSoup\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'all_urls' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0dbRTZdTeeiX",
        "colab_type": "code",
        "outputId": "07ab0251-bf5b-437f-ed97-69254758384f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 131
        }
      },
      "source": [
        "div = soup.find('div,{'class':'storytext'})\n",
        "div.get_text()\n",
        "text = tex.encode(\"ascii\", \"ignore\")\n",
        "text[:500]                "
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "error",
          "ename": "SyntaxError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-12-964028ccc21a>\"\u001b[0;36m, line \u001b[0;32m1\u001b[0m\n\u001b[0;31m    div = soup.find('div,{'class':'storytext'})\u001b[0m\n\u001b[0m                               ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0kHwE6QFfoU0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#now let's write it to a file\n",
        "story_id = url.split(\"/\")[4]\n",
        "filename = \"hp/\" + story_id + \".txt\"\n",
        "with open(filename, 'w') as f:\n",
        "  f.write(text)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x_uh2pGgf-Yh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#That was pretty easy. Let's grab all of them and save them to\n",
        "# a file named after their story id from the URL\n",
        "all_texts = []\n",
        "for url in all_urls:\n",
        "  story_id = url.split(\"/\")[4]\n",
        "  filename = \"hp/\" + story_id + \".txt\"\n",
        "  page = urllib2.urlopen(url)\n",
        "  soup = BeautifulSoup(page.read())\n",
        "  div = soup.find('div',{'class':'storytext'})\n",
        "  text = text.encode(\"ascii\",\"ignore\")\n",
        "  with open(filename, 'w') as f:\n",
        "    f.write(text)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IcSIc0XUWAtw",
        "colab_type": "text"
      },
      "source": [
        "Here is the page I am copying from:\n",
        "https://nbviewer.jupyter.org/github/ledeprogram/courses/blob/master/algorithms/07%20HP%20Scraper.ipynb"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BT9gdS7viJZa",
        "colab_type": "text"
      },
      "source": [
        "### Assignment questions\n",
        "\n",
        "After you've worked on some code, answer the following questions in this text block:\n",
        "\n",
        "1.  Describe in a paragraph of text what you did and why, as if you were writing an email to somebody interested but nontechnical.\n",
        "\n",
        "2.  What was the most challenging part of what you did?\n",
        "\n",
        "3.  What was the most interesting thing you learned?\n",
        "\n",
        "4.  What area would you like to explore with more time?\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pPvUiCQpg2t5",
        "colab_type": "text"
      },
      "source": [
        "1) I copied (retyped) a Python scraping program. The original program sraped a Harry Potter fan fiction site. I substituted a different website. The original code did not work. The first error had to do with teh \"urllib2\" import and commands associated with it. I found some recommendations on this in Stackoverflow, but have not been able to make it work yet. Even though the code contains errors, copying it gave me a better sense of looping with for lists and constructing new lsits. I learned about .extend in addition to .append. I imagine that scraping webistes successfully would yield some interesting data sets.\n",
        "\n",
        "2) Trying to find a solution to the urllib2 that would work in Python 3.\n",
        "\n",
        "3) That finding solutions should be much easier than it is, and that there is a real tension between open source and responsible editing. \n",
        "\n",
        "4) I would like to get this working and actually compare data by scraping websites. I'd also like to see if there is a way to analyze argument structure of content on websites to predict popularity and rhetorical effectiveness. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_XXg2crAipwP",
        "colab_type": "text"
      },
      "source": [
        "## Stretch goals and resources\n",
        "\n",
        "Following are *optional* things for you to take a look at. Focus on the above assignment first, and make sure to commit and push your changes to GitHub (and since this is the first assignment of the sprint, open a PR as well).\n",
        "\n",
        "- [pandas documentation](https://pandas.pydata.org/pandas-docs/stable/)\n",
        "- [scikit-learn documentation](http://scikit-learn.org/stable/documentation.html)\n",
        "- [matplotlib documentation](https://matplotlib.org/contents.html)\n",
        "- [Awesome Data Science](https://github.com/bulutyazilim/awesome-datascience) - a list of many types of DS resources\n",
        "\n",
        "Stretch goals:\n",
        "\n",
        "- Find and read blogs, walkthroughs, and other examples of people working through cool things with data science - and share with your classmates!\n",
        "- Write a blog post (Medium is a popular place to publish) introducing yourself as somebody learning data science, and talking about what you've learned already and what you're excited to learn more about."
      ]
    }
  ]
}