{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "LS_DS_111_A_First_Look_at_Data.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/eyvonne/DS-Unit-1-Sprint-1-Dealing-With-Data/blob/master/LS_DS_111_A_First_Look_at_Data.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Okfr_uhwhS1X",
        "colab_type": "text"
      },
      "source": [
        "# Lambda School Data Science - A First Look at Data\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9dtJETFRhnOG",
        "colab_type": "text"
      },
      "source": [
        "## Lecture - let's explore Python DS libraries and examples!\n",
        "\n",
        "The Python Data Science ecosystem is huge. You've seen some of the big pieces - pandas, scikit-learn, matplotlib. What parts do you want to see more of?"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WiBkgmPJhmhE",
        "colab_type": "code",
        "outputId": "04551cff-e1b5-4825-825d-ce8544c35e55",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "2+2"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "4"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 1
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lOqaPds9huME",
        "colab_type": "text"
      },
      "source": [
        "## Assignment - now it's your turn\n",
        "\n",
        "Pick at least one Python DS library, and using documentation/examples reproduce in this notebook something cool. It's OK if you don't fully understand it or get it 100% working, but do put in effort and look things up."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TGUS79cOhPWj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pandas as pd\n",
        "from google.colab import files\n",
        "from collections import Counter\n",
        "from sklearn.utils import shuffle"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8VXWPkx3opX1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.feature_extraction.text import CountVectorizer \n",
        "from sklearn.feature_extraction.text import TfidfTransformer \n",
        "from sklearn.naive_bayes import MultinomialNB \n",
        "from sklearn.pipeline import Pipeline \n",
        "from sklearn import metrics \n",
        "import numpy as np\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nQ0dSSn9Z2YT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "titles = []\n",
        "categories = []\n",
        "labels = []\n",
        "nlabels = 4\n",
        "lnews = []"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TAbSxlrsaE55",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def import_data():\n",
        "  global titles, labels, categories\n",
        "  news=pd.read_csv('https://github.com/eyvonne/csvFiles/blob/master/newsCorpora.csv?raw=true') \n",
        "  print(news.head())\n",
        "  categories=news[\"Category\"]\n",
        "  titles=news[\"Title\"]\n",
        "  labels=sorted(list(set(categories)))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TYB7E9r5adAL",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 254
        },
        "outputId": "a826c941-7500-47e9-f8b7-89418377ed68"
      },
      "source": [
        "%time import_data()"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "   1  ... Unnamed: 8\n",
            "0  2  ...        NaN\n",
            "1  3  ...        NaN\n",
            "2  4  ...        NaN\n",
            "3  5  ...        NaN\n",
            "4  6  ...        NaN\n",
            "\n",
            "[5 rows x 9 columns]\n",
            "CPU times: user 393 ms, sys: 30.5 ms, total: 423 ms\n",
            "Wall time: 1.13 s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lxObcJvkqmPt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "af9crDTfjDN3",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 164
        },
        "outputId": "8cbbbf21-a3fe-4c70-ab87-71aeb88c6d72"
      },
      "source": [
        "def count_data(labels, categories):\n",
        "  c=Counter(categories)\n",
        "  cont=dict(c)\n",
        "  tot=sum(list(cont.values()))\n",
        "  d={\n",
        "      \"category\" : labels,\n",
        "      \"news\" : [cont[l] for l in labels],\n",
        "      \"percent\" : [cont[l]/tot for l in labels]\n",
        "  }\n",
        "  print(pd.DataFrame(d))\n",
        "  print('total \\t', tot)\n",
        "  return cont\n",
        "cont=count_data(labels, categories)"
      ],
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "  category   news   percent\n",
            "0        b  19390  0.295877\n",
            "1        e  22258  0.339640\n",
            "2        m   7528  0.114872\n",
            "3        t  16358  0.249611\n",
            "total \t 65534\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vaO7jLZVqr27",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PkOE2tqqkihw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "x_train = []\n",
        "y_train =[]\n",
        "x_test=[]\n",
        "y_test=[]\n",
        "\n",
        "def split():\n",
        "  global titles, categories\n",
        "  global x_train, y_train, x_test, y_test\n",
        "  n=len(titles)\n",
        "  Ntrain=int(n*.7) \n",
        "  titles, categories = shuffle(titles, categories, random_state=0)\n",
        "  x_train=titles[:Ntrain]\n",
        "  y_train=categories[:Ntrain]\n",
        "  x_test=titles[Ntrain:]\n",
        "  y_test=categories[Ntrain:]\n",
        "\n",
        "split()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cH4aouIxrJyM",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 164
        },
        "outputId": "d8e84cdd-6b08-4b13-bc83-a75b4c2d6e86"
      },
      "source": [
        "cont2=count_data(labels, y_train)"
      ],
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "  category   news   percent\n",
            "0        b  13609  0.296667\n",
            "1        e  15440  0.336581\n",
            "2        m   5310  0.115754\n",
            "3        t  11514  0.250997\n",
            "total \t 45873\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eqVLeN5mosAM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def train_test():\n",
        "  global x_train, y_train, x_test, y_test, labels \n",
        "  text_clf = Pipeline([('vect', CountVectorizer()), #get the data word by word\n",
        "                       ('tfidf', TfidfTransformer()), #get the inverse frequency\n",
        "                       ('clf', MultinomialNB()), #do some clever math\n",
        "                       ])\n",
        "  text_clf = text_clf.fit(x_train, y_train)\n",
        "  predicted = text_clf.predict(x_test)\n",
        "  return predicted\n",
        "predicted=train_test()  "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sIl0DnQIr-jI",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 75
        },
        "outputId": "25346ba1-04e8-415e-d82a-7ae6ab0342c9"
      },
      "source": [
        "metrics.accuracy_score(y_test, predicted)"
      ],
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.9421189156197548"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 48
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0pW6Y3PLkh8W",
        "colab_type": "text"
      },
      "source": [
        "This is a natural language processing tool which classifies articles based on their titles into a group. It does this by first taking each word of the title. From there it looks at the word frequency, and then orders them inversly to mostly eliminate words that occur regularly ('a', 'the', 'and', etc) that don't have a substantial impact on the title. It then uses this list and does some statistical analysis (called a Multinomial Naive Bayes) which to dramatically oversimplify looks at the total number of words used and what category they are most likely in. \n",
        "Surprisingly the most challenging part of this was getting the CSV file to read, between upload limits on most of the places I was attempting to save it and getting the wrong file it took quite a bit of manipulation to get it into the right shape and place. The most interesting piece for me was definitly the Naive Bayes, and given more time is what I want to read more on. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BT9gdS7viJZa",
        "colab_type": "text"
      },
      "source": [
        "### Assignment questions\n",
        "\n",
        "After you've worked on some code, answer the following questions in this text block:\n",
        "\n",
        "1.  Describe in a paragraph of text what you did and why, as if you were writing an email to somebody interested but nontechnical.\n",
        "\n",
        "2.  What was the most challenging part of what you did?\n",
        "\n",
        "3.  What was the most interesting thing you learned?\n",
        "\n",
        "4.  What area would you like to explore with more time?\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hWdIRjE-xAaw",
        "colab_type": "text"
      },
      "source": [
        "surprisingly my biggest"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_XXg2crAipwP",
        "colab_type": "text"
      },
      "source": [
        "## Stretch goals and resources\n",
        "\n",
        "Following are *optional* things for you to take a look at. Focus on the above assignment first, and make sure to commit and push your changes to GitHub (and since this is the first assignment of the sprint, open a PR as well).\n",
        "\n",
        "- [pandas documentation](https://pandas.pydata.org/pandas-docs/stable/)\n",
        "- [scikit-learn documentation](http://scikit-learn.org/stable/documentation.html)\n",
        "- [matplotlib documentation](https://matplotlib.org/contents.html)\n",
        "- [Awesome Data Science](https://github.com/bulutyazilim/awesome-datascience) - a list of many types of DS resources\n",
        "\n",
        "Stretch goals:\n",
        "\n",
        "- Find and read blogs, walkthroughs, and other examples of people working through cool things with data science - and share with your classmates!\n",
        "- Write a blog post (Medium is a popular place to publish) introducing yourself as somebody learning data science, and talking about what you've learned already and what you're excited to learn more about."
      ]
    }
  ]
}