{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "LS_DS_111_A_First_Look_at_Data.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/strangelycutlemon/DS-Unit-1-Sprint-1-Dealing-With-Data/blob/master/LS_DS_111_A_First_Look_at_Data.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Okfr_uhwhS1X",
        "colab_type": "text"
      },
      "source": [
        "# Lambda School Data Science - A First Look at Data\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9dtJETFRhnOG",
        "colab_type": "text"
      },
      "source": [
        "## Lecture - let's explore Python DS libraries and examples!\n",
        "\n",
        "The Python Data Science ecosystem is huge. You've seen some of the big pieces - pandas, scikit-learn, matplotlib. What parts do you want to see more of?"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WiBkgmPJhmhE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#testing changes\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GJ0oeTTIQ4A6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RForL50AUbu9",
        "colab_type": "code",
        "outputId": "6bbafd25-0098-4664-b3ee-6e799b8d3126",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 370
        }
      },
      "source": [
        "import gym\n",
        "\n",
        "#cartpole test\n",
        "env = gym.make('CartPole-v0')\n",
        "env.reset()\n",
        "for _ in range(1000):\n",
        "  env.render()\n",
        "  env.step(env.action_space.sample())\n",
        "env.close()"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NoSuchDisplayException",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNoSuchDisplayException\u001b[0m                    Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-19-10bc64768dd5>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0menv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0m_\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1000\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m   \u001b[0menv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrender\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m   \u001b[0menv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0menv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maction_space\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msample\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0menv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/gym/core.py\u001b[0m in \u001b[0;36mrender\u001b[0;34m(self, mode, **kwargs)\u001b[0m\n\u001b[1;32m    274\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    275\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mrender\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'human'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 276\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrender\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    277\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    278\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/gym/envs/classic_control/cartpole.py\u001b[0m in \u001b[0;36mrender\u001b[0;34m(self, mode)\u001b[0m\n\u001b[1;32m    148\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    149\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mviewer\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 150\u001b[0;31m             \u001b[0;32mfrom\u001b[0m \u001b[0mgym\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menvs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclassic_control\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mrendering\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    151\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mviewer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrendering\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mViewer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mscreen_width\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscreen_height\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    152\u001b[0m             \u001b[0ml\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mr\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0mcartwidth\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcartwidth\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcartheight\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0mcartheight\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/gym/envs/classic_control/rendering.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 23\u001b[0;31m     \u001b[0;32mfrom\u001b[0m \u001b[0mpyglet\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgl\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     24\u001b[0m \u001b[0;32mexcept\u001b[0m \u001b[0mImportError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m     \u001b[0mreraise\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprefix\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"Error occured while running `from pyglet.gl import *`\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0msuffix\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"HINT: make sure you have OpenGL install. On Ubuntu, you can run 'apt-get install python-opengl'. If you're running on a server, you may need a virtual frame buffer; something like this should work: 'xvfb-run -s \\\"-screen 0 1400x900x24\\\" python <your_script.py>'\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pyglet/gl/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    235\u001b[0m     \u001b[0;31m# trickery is for circular import\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    236\u001b[0m     \u001b[0m_pyglet\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgl\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_sys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodules\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0m__name__\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 237\u001b[0;31m     \u001b[0;32mimport\u001b[0m \u001b[0mpyglet\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwindow\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pyglet/window/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m   1869\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0m_is_epydoc\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1870\u001b[0m     \u001b[0mpyglet\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwindow\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodules\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0m__name__\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1871\u001b[0;31m     \u001b[0mgl\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_create_shadow_window\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pyglet/gl/__init__.py\u001b[0m in \u001b[0;36m_create_shadow_window\u001b[0;34m()\u001b[0m\n\u001b[1;32m    207\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    208\u001b[0m     \u001b[0;32mfrom\u001b[0m \u001b[0mpyglet\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwindow\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mWindow\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 209\u001b[0;31m     \u001b[0m_shadow_window\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mWindow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwidth\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mheight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvisible\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    210\u001b[0m     \u001b[0m_shadow_window\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mswitch_to\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    211\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pyglet/window/xlib/__init__.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    169\u001b[0m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_event_handlers\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    170\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 171\u001b[0;31m         \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mXlibWindow\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    172\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    173\u001b[0m         \u001b[0;32mglobal\u001b[0m \u001b[0m_can_detect_autorepeat\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pyglet/window/__init__.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, width, height, caption, resizable, style, fullscreen, visible, vsync, display, screen, config, context, mode)\u001b[0m\n\u001b[1;32m    572\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    573\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mdisplay\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 574\u001b[0;31m             \u001b[0mdisplay\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpyglet\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcanvas\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_display\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    575\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    576\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mscreen\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pyglet/canvas/__init__.py\u001b[0m in \u001b[0;36mget_display\u001b[0;34m()\u001b[0m\n\u001b[1;32m     94\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     95\u001b[0m     \u001b[0;31m# Otherwise, create a new display and return it.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 96\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mDisplay\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     97\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     98\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pyglet/canvas/xlib.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, name, x_screen)\u001b[0m\n\u001b[1;32m    118\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_display\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mxlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mXOpenDisplay\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    119\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_display\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 120\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mNoSuchDisplayException\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Cannot connect to \"%s\"'\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    121\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    122\u001b[0m         \u001b[0mscreen_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mxlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mXScreenCount\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_display\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNoSuchDisplayException\u001b[0m: Cannot connect to \"None\""
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V4Ks7dE7XE_9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# looks like a problem with how installed packages are accessed on this runtime?\n",
        "# It works perfectly when I run it in terminal. \n",
        "# Ah. The problem comes from Colab's inability to display WebGL. There is a complicated workaround\n",
        "# But I'm likely to learn more if I pick a different DS library entirely.\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Vt3qrzqCXEuC",
        "colab_type": "text"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Cm8-AwVHXEbD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lOqaPds9huME",
        "colab_type": "text"
      },
      "source": [
        "## Assignment - now it's your turn\n",
        "\n",
        "Pick at least one Python DS library, and using documentation/examples reproduce in this notebook something cool. It's OK if you don't fully understand it or get it 100% working, but do put in effort and look things up."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TGUS79cOhPWj",
        "colab_type": "code",
        "outputId": "3510b49f-c0e2-4d78-9772-8616d63c7eed",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "import nltk\n",
        "nltk.download()\n",
        "\n",
        "\n"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "NLTK Downloader\n",
            "---------------------------------------------------------------------------\n",
            "    d) Download   l) List    u) Update   c) Config   h) Help   q) Quit\n",
            "---------------------------------------------------------------------------\n",
            "Downloader> book\n",
            "Command 'book' unrecognized\n",
            "\n",
            "---------------------------------------------------------------------------\n",
            "    d) Download   l) List    u) Update   c) Config   h) Help   q) Quit\n",
            "---------------------------------------------------------------------------\n",
            "Downloader> d\n",
            "\n",
            "Download which package (l=list; x=cancel)?\n",
            "  Identifier> book\n",
            "    Downloading collection 'book'\n",
            "       | \n",
            "       | Downloading package abc to /root/nltk_data...\n",
            "       |   Package abc is already up-to-date!\n",
            "       | Downloading package brown to /root/nltk_data...\n",
            "       |   Package brown is already up-to-date!\n",
            "       | Downloading package chat80 to /root/nltk_data...\n",
            "       |   Package chat80 is already up-to-date!\n",
            "       | Downloading package cmudict to /root/nltk_data...\n",
            "       |   Package cmudict is already up-to-date!\n",
            "       | Downloading package conll2000 to /root/nltk_data...\n",
            "       |   Package conll2000 is already up-to-date!\n",
            "       | Downloading package conll2002 to /root/nltk_data...\n",
            "       |   Package conll2002 is already up-to-date!\n",
            "       | Downloading package dependency_treebank to /root/nltk_data...\n",
            "       |   Package dependency_treebank is already up-to-date!\n",
            "       | Downloading package genesis to /root/nltk_data...\n",
            "       |   Package genesis is already up-to-date!\n",
            "       | Downloading package gutenberg to /root/nltk_data...\n",
            "       |   Package gutenberg is already up-to-date!\n",
            "       | Downloading package ieer to /root/nltk_data...\n",
            "       |   Package ieer is already up-to-date!\n",
            "       | Downloading package inaugural to /root/nltk_data...\n",
            "       |   Package inaugural is already up-to-date!\n",
            "       | Downloading package movie_reviews to /root/nltk_data...\n",
            "       |   Package movie_reviews is already up-to-date!\n",
            "       | Downloading package nps_chat to /root/nltk_data...\n",
            "       |   Package nps_chat is already up-to-date!\n",
            "       | Downloading package names to /root/nltk_data...\n",
            "       |   Package names is already up-to-date!\n",
            "       | Downloading package ppattach to /root/nltk_data...\n",
            "       |   Package ppattach is already up-to-date!\n",
            "       | Downloading package reuters to /root/nltk_data...\n",
            "       |   Package reuters is already up-to-date!\n",
            "       | Downloading package senseval to /root/nltk_data...\n",
            "       |   Package senseval is already up-to-date!\n",
            "       | Downloading package state_union to /root/nltk_data...\n",
            "       |   Package state_union is already up-to-date!\n",
            "       | Downloading package stopwords to /root/nltk_data...\n",
            "       |   Package stopwords is already up-to-date!\n",
            "       | Downloading package swadesh to /root/nltk_data...\n",
            "       |   Package swadesh is already up-to-date!\n",
            "       | Downloading package timit to /root/nltk_data...\n",
            "       |   Package timit is already up-to-date!\n",
            "       | Downloading package treebank to /root/nltk_data...\n",
            "       |   Package treebank is already up-to-date!\n",
            "       | Downloading package toolbox to /root/nltk_data...\n",
            "       |   Package toolbox is already up-to-date!\n",
            "       | Downloading package udhr to /root/nltk_data...\n",
            "       |   Package udhr is already up-to-date!\n",
            "       | Downloading package udhr2 to /root/nltk_data...\n",
            "       |   Package udhr2 is already up-to-date!\n",
            "       | Downloading package unicode_samples to /root/nltk_data...\n",
            "       |   Package unicode_samples is already up-to-date!\n",
            "       | Downloading package webtext to /root/nltk_data...\n",
            "       |   Package webtext is already up-to-date!\n",
            "       | Downloading package wordnet to /root/nltk_data...\n",
            "       |   Package wordnet is already up-to-date!\n",
            "       | Downloading package wordnet_ic to /root/nltk_data...\n",
            "       |   Package wordnet_ic is already up-to-date!\n",
            "       | Downloading package words to /root/nltk_data...\n",
            "       |   Package words is already up-to-date!\n",
            "       | Downloading package maxent_treebank_pos_tagger to\n",
            "       |     /root/nltk_data...\n",
            "       |   Package maxent_treebank_pos_tagger is already up-to-date!\n",
            "       | Downloading package maxent_ne_chunker to /root/nltk_data...\n",
            "       |   Package maxent_ne_chunker is already up-to-date!\n",
            "       | Downloading package universal_tagset to /root/nltk_data...\n",
            "       |   Package universal_tagset is already up-to-date!\n",
            "       | Downloading package punkt to /root/nltk_data...\n",
            "       |   Package punkt is already up-to-date!\n",
            "       | Downloading package book_grammars to /root/nltk_data...\n",
            "       |   Package book_grammars is already up-to-date!\n",
            "       | Downloading package city_database to /root/nltk_data...\n",
            "       |   Package city_database is already up-to-date!\n",
            "       | Downloading package tagsets to /root/nltk_data...\n",
            "       |   Package tagsets is already up-to-date!\n",
            "       | Downloading package panlex_swadesh to /root/nltk_data...\n",
            "       |   Package panlex_swadesh is already up-to-date!\n",
            "       | Downloading package averaged_perceptron_tagger to\n",
            "       |     /root/nltk_data...\n",
            "       |   Package averaged_perceptron_tagger is already up-to-date!\n",
            "       | \n",
            "     Done downloading collection book\n",
            "\n",
            "---------------------------------------------------------------------------\n",
            "    d) Download   l) List    u) Update   c) Config   h) Help   q) Quit\n",
            "---------------------------------------------------------------------------\n",
            "Downloader> q\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "utbYEWXeYRwO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from nltk.book import *"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XggQ0WIaaICQ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "43486d80-3a43-4ff1-e296-df76c29b1865"
      },
      "source": [
        "# Ooh. text9 is one of my favorite books! Let's play with that.\n",
        "\n",
        "text9"
      ],
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<Text: The Man Who Was Thursday by G . K . Chesterton 1908>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 43
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MBdIUtlraiqz",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 823
        },
        "outputId": "8ba53142-0cb2-44b9-dd85-c6fd4ad50489"
      },
      "source": [
        "dir(text9)"
      ],
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['_CONTEXT_RE',\n",
              " '_COPY_TOKENS',\n",
              " '__class__',\n",
              " '__delattr__',\n",
              " '__dict__',\n",
              " '__dir__',\n",
              " '__doc__',\n",
              " '__eq__',\n",
              " '__format__',\n",
              " '__ge__',\n",
              " '__getattribute__',\n",
              " '__getitem__',\n",
              " '__gt__',\n",
              " '__hash__',\n",
              " '__init__',\n",
              " '__init_subclass__',\n",
              " '__le__',\n",
              " '__len__',\n",
              " '__lt__',\n",
              " '__module__',\n",
              " '__ne__',\n",
              " '__new__',\n",
              " '__reduce__',\n",
              " '__reduce_ex__',\n",
              " '__repr__',\n",
              " '__setattr__',\n",
              " '__sizeof__',\n",
              " '__str__',\n",
              " '__subclasshook__',\n",
              " '__unicode__',\n",
              " '__weakref__',\n",
              " '_context',\n",
              " '_token_searcher',\n",
              " 'collocations',\n",
              " 'common_contexts',\n",
              " 'concordance',\n",
              " 'count',\n",
              " 'dispersion_plot',\n",
              " 'findall',\n",
              " 'generate',\n",
              " 'index',\n",
              " 'name',\n",
              " 'plot',\n",
              " 'readability',\n",
              " 'similar',\n",
              " 'tokens',\n",
              " 'unicode_repr',\n",
              " 'vocab']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 44
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2XD_XJNRaim-",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "3d5cf184-ce44-466a-80fc-5fad59070851"
      },
      "source": [
        "len(text9)"
      ],
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "69213"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 45
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "POsOTkYIaiks",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 185
        },
        "outputId": "8b7107ed-0b73-4e09-b544-f6c3f3f837bb"
      },
      "source": [
        "from nltk import collocations\n",
        "\n",
        "BigramCollocationFinder = nltk.collocations.BigramCollocationFinder\n",
        "\n",
        "bigram_measures = nltk.collocations.BigramAssocMeasures()\n",
        "trigram_measures = nltk.collocations.TrigramAssocMeasures()\n",
        "finder = BigramCollocationFinder.from_words(text9)\n",
        "'''\n",
        "Find the top 10 most strongly correlated pairs of words in the book that\n",
        "appear at least 3 times\n",
        "'''\n",
        "finder.apply_freq_filter(3)\n",
        "finder.nbest(bigram_measures.pmi, 10)\n"
      ],
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('Scotland', 'Yard'),\n",
              " ('Chinese', 'lanterns'),\n",
              " ('Baker', 'Street'),\n",
              " ('wax', 'lady'),\n",
              " ('Central', 'Anarchist'),\n",
              " ('Saffron', 'Park'),\n",
              " ('outer', 'ring'),\n",
              " ('Leicester', 'Square'),\n",
              " ('cheers', ').'),\n",
              " ('inner', 'ring')]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 46
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Xqkh5_Qiaiif",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 185
        },
        "outputId": "6737253d-35f0-48a7-fd81-f6c617c6273d"
      },
      "source": [
        "'''Try spanning intervening words between the paired words.'''\n",
        "finder = BigramCollocationFinder.from_words(text9, window_size=20)\n",
        "finder.apply_freq_filter(3)\n",
        "# ignore stopwords and short words\n",
        "ignored_words = nltk.corpus.stopwords.words('english') \n",
        "finder.apply_word_filter(lambda w: len(w) < 3 or w.lower() in ignored_words)\n",
        "finder.nbest(bigram_measures.pmi, 10)"
      ],
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('epic', 'iliad'),\n",
              " ('barking', 'bark'),\n",
              " ('beetles', 'barking'),\n",
              " ('commemorates', 'Bradshaw'),\n",
              " ('contain', 'dining'),\n",
              " ('destroys', 'broadens'),\n",
              " ('expand', 'breaks'),\n",
              " ('hedgehog', 'Montaigne'),\n",
              " ('objected', 'governed'),\n",
              " ('inquisitive', 'betray')]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 47
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ts_mGB5Eaid8",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 185
        },
        "outputId": "902852bf-9072-4a78-e4b6-2fadfee43049"
      },
      "source": [
        "# trigrams\n",
        "finder.nbest(trigram_measures.pmi, 10)\n",
        "# ? trigrams give almost identical results. I wonder if there's a problem here.\n",
        "# OH. finder is set to use BigramCollocationFinder of course. so these results\n",
        "# are scored using the bigram collocation strength."
      ],
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('epic', 'iliad'),\n",
              " ('barking', 'bark'),\n",
              " ('beetles', 'barking'),\n",
              " ('commemorates', 'Bradshaw'),\n",
              " ('contain', 'dining'),\n",
              " ('destroys', 'broadens'),\n",
              " ('expand', 'breaks'),\n",
              " ('hedgehog', 'Montaigne'),\n",
              " ('objected', 'governed'),\n",
              " ('Thieves', 'property')]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 48
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vGuGsGL0aiV1",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 185
        },
        "outputId": "fbd6c25b-2263-4025-f449-eac4f5d8acf7"
      },
      "source": [
        "# bigrams using LR instead of PMI\n",
        "finder.nbest(bigram_measures.likelihood_ratio, 10)\n",
        "# Why is \"think\" paired with \"think\"?\n",
        "# These results seem to make more sense than the PMI results above though."
      ],
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('outer', 'ring'),\n",
              " ('said', 'Syme'),\n",
              " ('ring', 'ring'),\n",
              " ('Comrade', 'Gregory'),\n",
              " ('property', 'property'),\n",
              " ('inner', 'ring'),\n",
              " ('Saffron', 'Park'),\n",
              " ('Leicester', 'Square'),\n",
              " ('think', 'think'),\n",
              " ('barrel', 'organ')]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 49
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GHVucjvhhZeY",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "outputId": "c435153f-258a-47a5-c2ac-45009165681a"
      },
      "source": [
        "'''\n",
        "Now we try to find collocations with particular words. I'll choose a couple from above.\n",
        "I'll make a separate filter for each word that gets us only the ngrams with it.\n",
        "'''\n",
        "\n",
        "anarchist_filter = lambda *w: 'anarchist' not in w\n",
        "think_filter = lambda *w: 'think' not in w\n",
        "\n",
        "\n",
        "# lowering the frequency requirement to 2 for now.\n",
        "finder = BigramCollocationFinder.from_words(text9, window_size=10)\n",
        "ignored_words = nltk.corpus.stopwords.words('english') \n",
        "finder.apply_word_filter(lambda w: len(w) < 3 or w.lower() in ignored_words)\n",
        "finder.apply_freq_filter(2)\n",
        "finder.apply_ngram_filter(anarchist_filter)\n",
        "print(finder.nbest(bigram_measures.likelihood_ratio,10))\n",
        "\n"
      ],
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[('anti', 'anarchist'), ('serious', 'anarchist'), ('charge', 'anarchist'), ('real', 'anarchist'), ('anarchist', 'Worms'), ('really', 'anarchist'), ('anarchist', 'Professor'), ('anarchist', 'cried'), ('anarchist', 'might'), ('might', 'anarchist')]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DHm-LG4Qg6r4",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "outputId": "032fce2c-9ade-480e-b4a6-857bcbb12d02"
      },
      "source": [
        "# try the other word.\n",
        "# Noticed that the finder object has to be re-defined to remove filters from\n",
        "# previous lines.\n",
        "\n",
        "finder = BigramCollocationFinder.from_words(text9, window_size=10)\n",
        "ignored_words = nltk.corpus.stopwords.words('english') \n",
        "finder.apply_word_filter(lambda w: len(w) < 3 or w.lower() in ignored_words)\n",
        "finder.apply_freq_filter(2)\n",
        "finder.apply_ngram_filter(think_filter)\n",
        "print(finder.nbest(bigram_measures.likelihood_ratio,10))"
      ],
      "execution_count": 58,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[('think', 'think'), ('think', 'flaneur'), ('think', 'wicked'), ('think', 'blew'), ('think', 'people'), ('think', 'said'), ('think', 'clearly'), ('cannot', 'think'), ('think', 'ordinary'), ('vaguely', 'think')]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AfT28iI8g6px",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "'''\n",
        "Resources used:\n",
        "\n",
        "https://textminingonline.com/dive-into-nltk-part-i-getting-started-with-nltk\n",
        "https://stackoverflow.com/questions/27795623/not-getting-the-required-output-using-wordnet-synsets-definition-method\n",
        "https://www.programcreek.com/python/example/106005/nltk.collocations.BigramCollocationFinder.from_words\n",
        "https://stackoverflow.com/questions/19145332/nltk-counting-frequency-of-bigram\n",
        "https://www.nltk.org/howto/collocations.html\n",
        "https://stackoverflow.com/questions/21165702/nltk-collocations-for-specific-words\n",
        "\n",
        "'''"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CwVyDHAWg6ky",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7845PstJg6id",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8e_dcGXRg6hF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0UAMecRwg6eO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BT9gdS7viJZa",
        "colab_type": "text"
      },
      "source": [
        "### Assignment questions\n",
        "\n",
        "After you've worked on some code, answer the following questions in this text block:\n",
        "\n",
        "1.  Describe in a paragraph of text what you did and why, as if you were writing an email to somebody interested but nontechnical.\n",
        "\n",
        "**I examined the text of GK Chesterton's book 'The Man Who Was Thursday' to find which words were commonly found together. This can tell you something about how the book is written, and what kinds of phrases one might find. Then I picked out two frequently-used words in particular and found their correlates as well.**\n",
        "\n",
        "2.  What was the most challenging part of what you did?\n",
        "\n",
        "**The first challenge was trying to get a completely different library (OpenAI Gym) working. I stopped trying after realizing that Colab doesn't support OpenGL, which largely defeats the point of using Gym.**\n",
        "\n",
        "**The second challenge was trying to search the NLTK documentation for info about the methods and metrics used with collocations. I eventually found that info but it's not very well indexed from what I've seen.**\n",
        "\n",
        "\n",
        "3.  What was the most interesting thing you learned?\n",
        "\n",
        "**I learned that finding collocations is surprisingly easy**\n",
        "\n",
        "4.  What area would you like to explore with more time?\n",
        "\n",
        "**- What else can you do once you've identified some good collocations?**\n",
        "\n",
        "**- Which association measures are better for different situations (Chi-square, PMI, LR, etc.)?**\n",
        "\n",
        "**- How would I write the finder to reuse the same code without typing new lines to reset the filters after each keyword?**\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BHigTu5JS7xf",
        "colab_type": "text"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_XXg2crAipwP",
        "colab_type": "text"
      },
      "source": [
        "## Stretch goals and resources\n",
        "\n",
        "Following are *optional* things for you to take a look at. Focus on the above assignment first, and make sure to commit and push your changes to GitHub (and since this is the first assignment of the sprint, open a PR as well).\n",
        "\n",
        "- [pandas documentation](https://pandas.pydata.org/pandas-docs/stable/)\n",
        "- [scikit-learn documentation](http://scikit-learn.org/stable/documentation.html)\n",
        "- [matplotlib documentation](https://matplotlib.org/contents.html)\n",
        "- [Awesome Data Science](https://github.com/bulutyazilim/awesome-datascience) - a list of many types of DS resources\n",
        "\n",
        "Stretch goals:\n",
        "\n",
        "- Find and read blogs, walkthroughs, and other examples of people working through cool things with data science - and share with your classmates!\n",
        "- Write a blog post (Medium is a popular place to publish) introducing yourself as somebody learning data science, and talking about what you've learned already and what you're excited to learn more about."
      ]
    }
  ]
}