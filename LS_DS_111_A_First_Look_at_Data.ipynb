{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "LS_DS_111_A_First_Look_at_Data.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/shmilyface/DS-Unit-1-Sprint-1-Dealing-With-Data/blob/master/LS_DS_111_A_First_Look_at_Data.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "metadata": {
        "id": "Okfr_uhwhS1X",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Lambda School Data Science - A First Look at Data\n",
        "\n"
      ]
    },
    {
      "metadata": {
        "id": "9dtJETFRhnOG",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Lecture - let's explore Python DS libraries and examples!\n",
        "\n",
        "The Python Data Science ecosystem is huge. You've seen some of the big pieces - pandas, scikit-learn, matplotlib. What parts do you want to see more of?"
      ]
    },
    {
      "metadata": {
        "id": "WiBkgmPJhmhE",
        "colab_type": "code",
        "outputId": "0ab4bde7-05aa-446a-a10e-ee9fde97c1fd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "# TODO - we'll be doing this live, taking requests\n",
        "# and reproducing what it is to look up and learn things\n",
        "print(\"Hello World\")\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Hello World\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "lOqaPds9huME",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Assignment - now it's your turn\n",
        "\n",
        "Pick at least one Python DS library, and using documentation/examples reproduce in this notebook something cool. It's OK if you don't fully understand it or get it 100% working, but do put in effort and look things up."
      ]
    },
    {
      "metadata": {
        "id": "TGUS79cOhPWj",
        "colab_type": "code",
        "outputId": "582b97c7-c5e3-4340-c47c-daabd67d7404",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 381
        }
      },
      "cell_type": "code",
      "source": [
        "#I chose pandas because a lot of what I'm reading says it's a great resource for building an understanding of how teaching computers work. \n",
        "from pandas import apply\n",
        "\n",
        "apply = pandas.apply #this function is being called to allow us to find missing values on either columns or rows\n",
        "\n",
        "def num_missing(x):\n",
        "  return sum(x.isnull()) # defining missing function\n",
        "\n",
        "print(\"Missing values per column:\", data.apply(num_missing, axis=0)) #0 for column, 1 for row\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ImportError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-17-e9be8a7a7898>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mpandas\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mapply\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mapply\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpandas\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m \u001b[0;31m#this function is being called to allow us to find missing values on either columns or rows\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mnum_missing\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mImportError\u001b[0m: cannot import name 'apply'",
            "",
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0;32m\nNOTE: If your import is failing due to a missing package, you can\nmanually install dependencies using either !pip or !apt.\n\nTo view examples of installing some common dependencies, click the\n\"Open Examples\" button below.\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n"
          ]
        }
      ]
    },
    {
      "metadata": {
        "id": "TQtqaG5qIsBq",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "df = pd.read_csv('https://raw.githubusercontent.com/ryanleeallred/datasets/master/titanic.csv', index_col=0)\n",
        "df = pd.DataFrame(df)\n",
        "\n",
        "apply = df.apply\n",
        "def num_missing(x):\n",
        "  return sum(x.isnull())\n",
        "print(\"Missing values per column:\", df.apply(num_missing, axis=1))\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "BT9gdS7viJZa",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Assignment questions\n",
        "\n",
        "After you've worked on some code, answer the following questions in this text block:\n",
        "\n",
        "1. ** Describe in a paragraph of text what you did and why, as if you were writing an email to somebody interested but nontechnical.**\n",
        "\n",
        "Python works well with third party libraries. Pandas is one of them! Sometimes when we're looking at spreadsheets of data for answers, we come across empty rows. That means whatever that specific category was, nothing was put down for that parameter. I like to think of it as someone filling out a medical release form, and marking the box to withhold their race or gender identity. The parameters are still there, but we don't have the information for those boxes. Pandas has a function called Apply. Apply takes a look at your data set, and comes back with a column by column, or row by row summary of where your missing boxes are. This is important for us as data scientists. That's because unless all of those empty boxes have something in them that makes sense and doesn't skew the data we're trying to study, our innocent little computer, who only knows exactly what we tell it, gets confused. This is a great way to get your bearings as you look at data sets.  \n",
        "\n",
        "\n",
        "2.  **What was the most challenging part of what you did?**\n",
        "\n",
        "I'd have to say researching. Definitely. I feel like when I try to research, I uncover more about what I don't know, than answers to what I need to know. It's hard to see through the noise of new information to find an answer to something I sort of know enough about, but not entirely. I was watching Elon Musk talk about the limitations of the neural networks in the Tesla fleet, and he said something that spoke to me, \"We don't know what we don't know\". I'm trying to figure out how to shore up this weakness, but I thrive with structure and a to do list I can loop through whenever I get to a point of confusion, and so far, my to do list is undefined. \n",
        "\n",
        "3.  **What was the most interesting thing you learned?**\n",
        "\n",
        "I learned so much today about the benefits of using and IDLE. I also learned how to use two terminal windows, one for coding, one for looking at the results, which I found to be a great, segmented way for me to test code and get instant results on what it would produce. But so far, I think the most interesting thing I learned was from watching 3 hours of Tesla engineers talk about neural networks. It was...if I had watched it a month ago, I don't think I could have followed it, but even after just the Pre Course and the first day of school, I'm impressed with \n",
        "\n",
        "4. ** What area would you like to explore with more time?**\n",
        "\n",
        "Definitely learning how to research. 100%. It's so foundational to being successful, and my need for structure is feeling like a hang up, and I feel that cementing a solid research philosophy and practice will really help me to succeed, since there's so much I want to understand. I feel like finding examples, implementing them like the exercise above, and making sure it works will help, but the lingo is definitely a barrier for me to work through as well. Each obstacle is it's own challenge, and I love that concept! Looking forward to refining my learning style and learning to trust the process! \n",
        "\n",
        "\n"
      ]
    },
    {
      "metadata": {
        "id": "_XXg2crAipwP",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Stretch goals and resources\n",
        "\n",
        "Following are *optional* things for you to take a look at. Focus on the above assignment first, and make sure to commit and push your changes to GitHub (and since this is the first assignment of the sprint, open a PR as well).\n",
        "\n",
        "- [pandas documentation](https://pandas.pydata.org/pandas-docs/stable/)\n",
        "- [scikit-learn documentation](http://scikit-learn.org/stable/documentation.html)\n",
        "- [matplotlib documentation](https://matplotlib.org/contents.html)\n",
        "- [Awesome Data Science](https://github.com/bulutyazilim/awesome-datascience) - a list of many types of DS resources\n",
        "\n",
        "Stretch goals:\n",
        "\n",
        "- Find and read blogs, walkthroughs, and other examples of people working through cool things with data science - and share with your classmates!\n",
        "- Write a blog post (Medium is a popular place to publish) introducing yourself as somebody learning data science, and talking about what you've learned already and what you're excited to learn more about."
      ]
    },
    {
      "metadata": {
        "id": "5QkCkSMlMIAN",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "My blog: \n",
        "https://medium.com/@shmilyface/an-ode-to-second-chances-5bdea5a2385f\n",
        "\n",
        "Resources: \n",
        "\n",
        "https://realpython.com/python-beginner-tips/ <---This is where I really began to learn about shells and how to use them. \n",
        "\n",
        "https://medium.com/@will.haeck/importing-kaggle-datasets-into-google-colab-86aed55483c3 <----this was a resource given to me in the ds_help stack. It was incredibly informative. \n",
        "\n"
      ]
    },
    {
      "metadata": {
        "id": "KljUvZ3mf90-",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Using Python, write code that quantifies the following data:\n",
        "\n",
        "Grow Mart, Plant Depot, and Trees’R’Us are gardening stores in a city. Grow Mart and Plant Depot were both founded in 1973, and Trees’R’Us was founded in 1985. Grow Mart has annual revenue of 265k and expenses of 183k, Plant Depot has 302k revenue and 240k expenses, and Trees’R’Us has 123k revenue and 130k expenses.\n",
        "\n",
        "In addition to describing the above, add a feature is_profitable. What sort of feature should this be, and how should it be determined?"
      ]
    },
    {
      "metadata": {
        "id": "Vw5u8aLZgBjk",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "Grow_Mart = {'founded': 1973, 'annual_revenue': 265000, 'annual_expenses':183000}\n",
        "Plant_Depot = {'founded': 1973, 'annual_revenue': 302000, 'annual_expenses':240000}\n",
        "Trees_R_Us = {'founded': 1985, 'annual_revenue': 123000, 'annual_expenses':130000}\n",
        "\n",
        "Gardening_Stores = [\n",
        "    Grow_Mart,\n",
        "    Plant_Depot,\n",
        "    Trees_R_Us\n",
        "]\n",
        "#feature should check to see if expenses are higher than the revenue.\n",
        "#I'll be using a True/False if statement to verify which stores made profit\n",
        "#and which ones did not. \n",
        "for x in Gardening_Stores:\n",
        "  x['bottom_line'] = x['annual_revenue'] - x['annual_expenses']\n",
        "  if x['bottom_line'] <= 0:\n",
        "    x['is_profitable'] = False\n",
        "  else:\n",
        "    x['is_profitable'] = True\n",
        "\n",
        "Gardening_Stores = pd.DataFrame(Gardening_Stores)\n",
        "\n",
        "print(Gardening_Stores)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "NUvrvdzAgE0M",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Logic Puzzle\n",
        "\n",
        "Active Clues\n",
        "1. The tube worm was found 1,500 feet higher up than the lancetfish.\n",
        "2. The specimen found at 19,500 ft was discovered in the Velma Deep.\n",
        "3. The specimen discovered in the Tethys Trough was found 1,500 feet lower down than the specimen discovered in the Fallon Deep.\n",
        "4. The anglerfish was found at 18,000 ft.\n",
        "5. The creature discovered in the Willis Trench was found somewhat lower down than the tube worm.\n",
        "\n",
        "![alt text](http://socratesdidnothingwrong.com/logic.jpg)"
      ]
    },
    {
      "metadata": {
        "id": "bJl_98p7gK3U",
        "colab_type": "code",
        "outputId": "6d4a6236-7c93-4cf9-b698-c2ca42a0f051",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 105
        }
      },
      "cell_type": "code",
      "source": [
        "\n",
        "#logic puzzle coding into dictionaries. \n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "anglerfish = {'animal':'Anglerfish', 'depth':'18000', 'locations':'Willis_Trench'}\n",
        "lanternfish = {'animal':'Lanternfish', 'depth':'19500', 'locations':'Velma_Deep'}\n",
        "lancerfish = {'animal': 'Lancerfish', 'depth':'16500', 'locations':'Tethys_Trough'}\n",
        "tube_worm = {'animal':'Tube_Fish', 'depth':'15000', 'locations':'Fallon Deep'}\n",
        "\n",
        "Fishy_Fish = [\n",
        "    anglerfish,\n",
        "    lanternfish,\n",
        "    lancerfish,\n",
        "    tube_worm\n",
        "]\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "Fishy_Fish = pd.DataFrame(Fishy_Fish)\n",
        "\n",
        "print(Fishy_Fish)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "        animal  depth      locations\n",
            "0   Anglerfish  18000  Willis_Trench\n",
            "1  Lanternfish  19500     Velma_Deep\n",
            "2   Lancerfish  16500  Tethys_Trough\n",
            "3    Tube_Fish  15000    Fallon Deep\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}