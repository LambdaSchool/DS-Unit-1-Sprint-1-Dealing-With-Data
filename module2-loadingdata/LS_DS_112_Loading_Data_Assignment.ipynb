{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "LS_DS_112_Loading_Data_Assignment.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "view-in-github"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ryanleeallred/DS-Unit-1-Sprint-1-Dealing-With-Data/blob/master/module2-loadingdata/LS_DS_112_Loading_Data_Assignment.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "MSnsTgZLKO72"
      },
      "source": [
        "# Practice Loading Datasets\n",
        "\n",
        "This assignment is purposely semi-open-ended you will be asked to load datasets both from github and also from CSV files from the [UC Irvine Machine Learning Repository](https://archive.ics.uci.edu/ml/index.php). \n",
        "\n",
        "Remember that the UCI datasets may not have a file type of `.csv` so it's important that you learn as much as you can about the dataset before you try and load it. See if you can look at the raw text of the file either locally, on github, using the `!curl` shell command, or in some other way before you try and read it in as a dataframe, this will help you catch what would otherwise be unforseen problems.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "156P6ndeKojO"
      },
      "source": [
        "## 1) Load a dataset from Github (via its *RAW* URL)\n",
        "\n",
        "Pick a dataset from the following repository and load it into Google Colab. Make sure that the headers are what you would expect and check to see if missing values have been encoded as NaN values:\n",
        "\n",
        "<https://github.com/ryanleeallred/datasets>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "NJdISe69ZT7E",
        "colab": {}
      },
      "source": [
        "# TODO your work here!\n",
        "# And note you should write comments, descriptions, and add new\n",
        "# code and text blocks as needed"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AocVsbZBx7Qa",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pandas as pd"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Wwb9_w0Gx7Qc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "?pd.read_csv "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BRXA0sQYx7Qe",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 850
        },
        "outputId": "37800558-e107-4b1d-fb78-5868a757e0f3"
      },
      "source": [
        "# even though it ends in csv doesn't actually return a csv file, must get from githubusercontent\n",
        "# pd.read_csv(\"https://github.com/ryanleeallred/datasets/blob/master/heart.csv\")\n",
        "heart = pd.read_csv(\"https://raw.githubusercontent.com/ryanleeallred/datasets/master/heart.csv\")\n",
        "# looks like no missing values have been encoded as NaN values\n",
        "print(heart.describe())\n",
        "print(heart.isna().sum()) \n",
        "print(heart.head(20))"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "              age         sex          cp  ...          ca        thal      target\n",
            "count  303.000000  303.000000  303.000000  ...  303.000000  303.000000  303.000000\n",
            "mean    54.366337    0.683168    0.966997  ...    0.729373    2.313531    0.544554\n",
            "std      9.082101    0.466011    1.032052  ...    1.022606    0.612277    0.498835\n",
            "min     29.000000    0.000000    0.000000  ...    0.000000    0.000000    0.000000\n",
            "25%     47.500000    0.000000    0.000000  ...    0.000000    2.000000    0.000000\n",
            "50%     55.000000    1.000000    1.000000  ...    0.000000    2.000000    1.000000\n",
            "75%     61.000000    1.000000    2.000000  ...    1.000000    3.000000    1.000000\n",
            "max     77.000000    1.000000    3.000000  ...    4.000000    3.000000    1.000000\n",
            "\n",
            "[8 rows x 14 columns]\n",
            "age         0\n",
            "sex         0\n",
            "cp          0\n",
            "trestbps    0\n",
            "chol        0\n",
            "fbs         0\n",
            "restecg     0\n",
            "thalach     0\n",
            "exang       0\n",
            "oldpeak     0\n",
            "slope       0\n",
            "ca          0\n",
            "thal        0\n",
            "target      0\n",
            "dtype: int64\n",
            "    age  sex  cp  trestbps  chol  fbs  ...  exang  oldpeak  slope  ca  thal  target\n",
            "0    63    1   3       145   233    1  ...      0      2.3      0   0     1       1\n",
            "1    37    1   2       130   250    0  ...      0      3.5      0   0     2       1\n",
            "2    41    0   1       130   204    0  ...      0      1.4      2   0     2       1\n",
            "3    56    1   1       120   236    0  ...      0      0.8      2   0     2       1\n",
            "4    57    0   0       120   354    0  ...      1      0.6      2   0     2       1\n",
            "5    57    1   0       140   192    0  ...      0      0.4      1   0     1       1\n",
            "6    56    0   1       140   294    0  ...      0      1.3      1   0     2       1\n",
            "7    44    1   1       120   263    0  ...      0      0.0      2   0     3       1\n",
            "8    52    1   2       172   199    1  ...      0      0.5      2   0     3       1\n",
            "9    57    1   2       150   168    0  ...      0      1.6      2   0     2       1\n",
            "10   54    1   0       140   239    0  ...      0      1.2      2   0     2       1\n",
            "11   48    0   2       130   275    0  ...      0      0.2      2   0     2       1\n",
            "12   49    1   1       130   266    0  ...      0      0.6      2   0     2       1\n",
            "13   64    1   3       110   211    0  ...      1      1.8      1   0     2       1\n",
            "14   58    0   3       150   283    1  ...      0      1.0      2   0     2       1\n",
            "15   50    0   2       120   219    0  ...      0      1.6      1   0     2       1\n",
            "16   58    0   2       120   340    0  ...      0      0.0      2   0     2       1\n",
            "17   66    0   3       150   226    0  ...      0      2.6      0   0     2       1\n",
            "18   43    1   0       150   247    0  ...      0      1.5      2   0     2       1\n",
            "19   69    0   3       140   239    0  ...      0      1.8      2   2     2       1\n",
            "\n",
            "[20 rows x 14 columns]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "-gFnZR6iLLPY"
      },
      "source": [
        "## 2) Load a dataset from your local machine\n",
        "Download a dataset from the [UC Irvine Machine Learning Repository](https://archive.ics.uci.edu/ml/index.php) and then upload the file to Google Colab either using the files tab in the left-hand sidebar or by importing `files` from `google.colab` The following link will be a useful resource if you can't remember the syntax: <https://towardsdatascience.com/3-ways-to-load-csv-files-into-colab-7c14fcbdcb92>\n",
        "\n",
        "While you are free to try and load any dataset from the UCI repository, I strongly suggest starting with one of the most popular datasets like those that are featured on the right-hand side of the home page. \n",
        "\n",
        "Some datasets on UCI will have challenges associated with importing them far beyond what we have exposed you to in class today, so if you run into a dataset that you don't know how to deal with, struggle with it for a little bit, but ultimately feel free to simply choose a different one. \n",
        "\n",
        "- Make sure that your file has correct headers, and the same number of rows and columns as is specified on the UCI page. If your dataset doesn't have headers use the parameters of the `read_csv` function to add them. Likewise make sure that missing values are encoded as `NaN`."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "qUmwX-ZoM9cq",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "0c3ba5f1-bbc0-4a21-bb03-2b8e12345678"
      },
      "source": [
        "# chose https://archive.ics.uci.edu/ml/datasets/Parkinson+Dataset+with+replicated+acoustic+features+\n",
        "parkinson = pd.read_csv(\"/content/ReplicatedAcousticFeatures-ParkinsonDatabase.csv\")\n",
        "print(parkinson.describe())\n",
        "print(parkinson.isna().sum()) \n",
        "print(parkinson.head(20))\n",
        "# No NaN values for this one either"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "        Recording      Status      Gender  ...     Delta10     Delta11     Delta12\n",
            "count  240.000000  240.000000  240.000000  ...  240.000000  240.000000  240.000000\n",
            "mean     2.000000    0.500000    0.400000  ...    1.331433    1.346381    1.346144\n",
            "std      0.818203    0.501045    0.490922  ...    0.211297    0.221484    0.208819\n",
            "min      1.000000    0.000000    0.000000  ...    0.777012    0.643132    0.748411\n",
            "25%      1.000000    0.000000    0.000000  ...    1.192397    1.202525    1.206559\n",
            "50%      2.000000    0.500000    0.000000  ...    1.333345    1.347297    1.331212\n",
            "75%      3.000000    1.000000    1.000000  ...    1.472589    1.506674    1.475235\n",
            "max      3.000000    1.000000    1.000000  ...    1.949679    1.918392    1.930103\n",
            "\n",
            "[8 rows x 47 columns]\n",
            "ID            0\n",
            "Recording     0\n",
            "Status        0\n",
            "Gender        0\n",
            "Jitter_rel    0\n",
            "Jitter_abs    0\n",
            "Jitter_RAP    0\n",
            "Jitter_PPQ    0\n",
            "Shim_loc      0\n",
            "Shim_dB       0\n",
            "Shim_APQ3     0\n",
            "Shim_APQ5     0\n",
            "Shi_APQ11     0\n",
            "HNR05         0\n",
            "HNR15         0\n",
            "HNR25         0\n",
            "HNR35         0\n",
            "HNR38         0\n",
            "RPDE          0\n",
            "DFA           0\n",
            "PPE           0\n",
            "GNE           0\n",
            "MFCC0         0\n",
            "MFCC1         0\n",
            "MFCC2         0\n",
            "MFCC3         0\n",
            "MFCC4         0\n",
            "MFCC5         0\n",
            "MFCC6         0\n",
            "MFCC7         0\n",
            "MFCC8         0\n",
            "MFCC9         0\n",
            "MFCC10        0\n",
            "MFCC11        0\n",
            "MFCC12        0\n",
            "Delta0        0\n",
            "Delta1        0\n",
            "Delta2        0\n",
            "Delta3        0\n",
            "Delta4        0\n",
            "Delta5        0\n",
            "Delta6        0\n",
            "Delta7        0\n",
            "Delta8        0\n",
            "Delta9        0\n",
            "Delta10       0\n",
            "Delta11       0\n",
            "Delta12       0\n",
            "dtype: int64\n",
            "         ID  Recording  Status  Gender  ...    Delta9   Delta10   Delta11   Delta12\n",
            "0   CONT-01          1       0       1  ...  1.403678  1.405495  1.416705  1.354610\n",
            "1   CONT-01          2       0       1  ...  1.322870  1.314549  1.318999  1.323508\n",
            "2   CONT-01          3       0       1  ...  1.438053  1.388910  1.305469  1.305402\n",
            "3   CONT-02          1       0       0  ...  1.551286  1.638346  1.604008  1.621456\n",
            "4   CONT-02          2       0       0  ...  1.640088  1.533666  1.297536  1.382023\n",
            "5   CONT-02          3       0       0  ...  1.625396  1.651655  1.652845  1.427623\n",
            "6   CONT-03          1       0       1  ...  1.345959  1.741863  1.828781  1.655604\n",
            "7   CONT-03          2       0       1  ...  1.526714  1.647910  1.662981  1.609652\n",
            "8   CONT-03          3       0       1  ...  1.447470  1.354798  1.585025  1.334293\n",
            "9   CONT-04          1       0       1  ...  1.579521  1.374581  1.550638  1.572821\n",
            "10  CONT-04          2       0       1  ...  1.555589  1.195330  1.555142  1.695319\n",
            "11  CONT-04          3       0       1  ...  1.773099  1.529496  1.760172  1.478536\n",
            "12  CONT-05          1       0       0  ...  1.385665  1.426097  1.515076  1.305066\n",
            "13  CONT-05          2       0       0  ...  1.464589  1.375371  1.358033  1.662816\n",
            "14  CONT-05          3       0       0  ...  1.545591  1.316806  1.377798  1.687215\n",
            "15  CONT-06          1       0       1  ...  1.429692  1.331124  1.408082  1.359682\n",
            "16  CONT-06          2       0       1  ...  1.529541  1.409931  1.477325  1.433082\n",
            "17  CONT-06          3       0       1  ...  1.385652  1.360055  1.347033  1.456393\n",
            "18  CONT-07          1       0       0  ...  1.514977  1.612537  1.790012  1.649126\n",
            "19  CONT-07          2       0       0  ...  1.538804  1.536038  1.534848  1.552188\n",
            "\n",
            "[20 rows x 48 columns]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "mq_aQjxlM-u5"
      },
      "source": [
        "## 3) Load a dataset from UCI using `!wget`\n",
        "\n",
        "\"Shell Out\" and try loading a file directly into your google colab's memory using the `!wget` command and then read it in with `read_csv`.\n",
        "\n",
        "With this file we'll do a bit more to it.\n",
        "\n",
        "- Read it in, fix any problems with the header as make sure missing values are encoded as `NaN`.\n",
        "- Use the `.fillna()` method to fill any missing values. \n",
        " - [.fillna() documentation](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.fillna.html)\n",
        "- Create one of each of the following plots using the Pandas plotting functionality:\n",
        " - Scatterplot\n",
        " - Histogram\n",
        " - Density Plot\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I6mAP6SRy1Be",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "outputId": "4c0bc989-e699-41d6-8cb0-8f211d7b5b94"
      },
      "source": [
        "!wget https://archive.ics.uci.edu/ml/machine-learning-databases/abalone/abalone.data"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2019-08-06 22:25:01--  https://archive.ics.uci.edu/ml/machine-learning-databases/abalone/abalone.data\n",
            "Resolving archive.ics.uci.edu (archive.ics.uci.edu)... 128.195.10.252\n",
            "Connecting to archive.ics.uci.edu (archive.ics.uci.edu)|128.195.10.252|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 191873 (187K) [application/x-httpd-php]\n",
            "Saving to: ‘abalone.data.2’\n",
            "\n",
            "\rabalone.data.2        0%[                    ]       0  --.-KB/s               \rabalone.data.2      100%[===================>] 187.38K  --.-KB/s    in 0.09s   \n",
            "\n",
            "2019-08-06 22:25:01 (1.99 MB/s) - ‘abalone.data.2’ saved [191873/191873]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1NTTsM0S2vxp",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 272
        },
        "outputId": "c928e6ea-58db-43f1-8243-27b96c9c9895"
      },
      "source": [
        "# show first 15 lines\n",
        "!cat /content/abalone.data |head -n 15"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "M,0.455,0.365,0.095,0.514,0.2245,0.101,0.15,15\n",
            "M,0.35,0.265,0.09,0.2255,0.0995,0.0485,0.07,7\n",
            "F,0.53,0.42,0.135,0.677,0.2565,0.1415,0.21,9\n",
            "M,0.44,0.365,0.125,0.516,0.2155,0.114,0.155,10\n",
            "I,0.33,0.255,0.08,0.205,0.0895,0.0395,0.055,7\n",
            "I,0.425,0.3,0.095,0.3515,0.141,0.0775,0.12,8\n",
            "F,0.53,0.415,0.15,0.7775,0.237,0.1415,0.33,20\n",
            "F,0.545,0.425,0.125,0.768,0.294,0.1495,0.26,16\n",
            "M,0.475,0.37,0.125,0.5095,0.2165,0.1125,0.165,9\n",
            "F,0.55,0.44,0.15,0.8945,0.3145,0.151,0.32,19\n",
            "F,0.525,0.38,0.14,0.6065,0.194,0.1475,0.21,14\n",
            "M,0.43,0.35,0.11,0.406,0.1675,0.081,0.135,10\n",
            "M,0.49,0.38,0.135,0.5415,0.2175,0.095,0.19,11\n",
            "F,0.535,0.405,0.145,0.6845,0.2725,0.171,0.205,10\n",
            "F,0.47,0.355,0.1,0.4755,0.1675,0.0805,0.185,10\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Cwb0BDMU3F_w",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "4f9243a0-5676-47f9-c13a-9adfd2a1ec3b"
      },
      "source": [
        "!wget https://archive.ics.uci.edu/ml/machine-learning-databases/abalone/abalone.names\n",
        "!cat /content/abalone.names"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2019-08-06 22:25:03--  https://archive.ics.uci.edu/ml/machine-learning-databases/abalone/abalone.names\n",
            "Resolving archive.ics.uci.edu (archive.ics.uci.edu)... 128.195.10.252\n",
            "Connecting to archive.ics.uci.edu (archive.ics.uci.edu)|128.195.10.252|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 4319 (4.2K) [application/x-httpd-php]\n",
            "Saving to: ‘abalone.names.1’\n",
            "\n",
            "\rabalone.names.1       0%[                    ]       0  --.-KB/s               \rabalone.names.1     100%[===================>]   4.22K  --.-KB/s    in 0s      \n",
            "\n",
            "2019-08-06 22:25:03 (119 MB/s) - ‘abalone.names.1’ saved [4319/4319]\n",
            "\n",
            "1. Title of Database: Abalone data\n",
            "\n",
            "2. Sources:\n",
            "\n",
            "   (a) Original owners of database:\n",
            "\tMarine Resources Division\n",
            "\tMarine Research Laboratories - Taroona\n",
            "\tDepartment of Primary Industry and Fisheries, Tasmania\n",
            "\tGPO Box 619F, Hobart, Tasmania 7001, Australia\n",
            "\t(contact: Warwick Nash +61 02 277277, wnash@dpi.tas.gov.au)\n",
            "\n",
            "   (b) Donor of database:\n",
            "\tSam Waugh (Sam.Waugh@cs.utas.edu.au)\n",
            "\tDepartment of Computer Science, University of Tasmania\n",
            "\tGPO Box 252C, Hobart, Tasmania 7001, Australia\n",
            "\n",
            "   (c) Date received: December 1995\n",
            "\n",
            "\n",
            "3. Past Usage:\n",
            "\n",
            "   Sam Waugh (1995) \"Extending and benchmarking Cascade-Correlation\", PhD\n",
            "   thesis, Computer Science Department, University of Tasmania.\n",
            "\n",
            "   -- Test set performance (final 1044 examples, first 3133 used for training):\n",
            "\t24.86% Cascade-Correlation (no hidden nodes)\n",
            "\t26.25% Cascade-Correlation (5 hidden nodes)\n",
            "\t21.5%  C4.5\n",
            "\t 0.0%  Linear Discriminate Analysis\n",
            "\t 3.57% k=5 Nearest Neighbour\n",
            "      (Problem encoded as a classification task)\n",
            "\n",
            "   -- Data set samples are highly overlapped.  Further information is required\n",
            "\tto separate completely using affine combinations.  Other restrictions\n",
            "\tto data set examined.\n",
            "\n",
            "   David Clark, Zoltan Schreter, Anthony Adams \"A Quantitative Comparison of\n",
            "   Dystal and Backpropagation\", submitted to the Australian Conference on\n",
            "   Neural Networks (ACNN'96). Data set treated as a 3-category classification\n",
            "   problem (grouping ring classes 1-8, 9 and 10, and 11 on).\n",
            "\n",
            "   -- Test set performance (3133 training, 1044 testing as above):\n",
            "\t64%    Backprop\n",
            "\t55%    Dystal\n",
            "   -- Previous work (Waugh, 1995) on same data set:\n",
            "\t61.40% Cascade-Correlation (no hidden nodes)\n",
            "\t65.61% Cascade-Correlation (5 hidden nodes)\n",
            "\t59.2%  C4.5\n",
            "\t32.57% Linear Discriminate Analysis\n",
            "\t62.46% k=5 Nearest Neighbour\n",
            "\n",
            "\n",
            "4. Relevant Information Paragraph:\n",
            "\n",
            "   Predicting the age of abalone from physical measurements.  The age of\n",
            "   abalone is determined by cutting the shell through the cone, staining it,\n",
            "   and counting the number of rings through a microscope -- a boring and\n",
            "   time-consuming task.  Other measurements, which are easier to obtain, are\n",
            "   used to predict the age.  Further information, such as weather patterns\n",
            "   and location (hence food availability) may be required to solve the problem.\n",
            "\n",
            "   From the original data examples with missing values were removed (the\n",
            "   majority having the predicted value missing), and the ranges of the\n",
            "   continuous values have been scaled for use with an ANN (by dividing by 200).\n",
            "\n",
            "   Data comes from an original (non-machine-learning) study:\n",
            "\n",
            "\tWarwick J Nash, Tracy L Sellers, Simon R Talbot, Andrew J Cawthorn and\n",
            "\tWes B Ford (1994) \"The Population Biology of Abalone (_Haliotis_\n",
            "\tspecies) in Tasmania. I. Blacklip Abalone (_H. rubra_) from the North\n",
            "\tCoast and Islands of Bass Strait\", Sea Fisheries Division, Technical\n",
            "\tReport No. 48 (ISSN 1034-3288)\n",
            "\n",
            "\n",
            "5. Number of Instances: 4177\n",
            "\n",
            "\n",
            "6. Number of Attributes: 8\n",
            "\n",
            "\n",
            "7. Attribute information:\n",
            "\n",
            "   Given is the attribute name, attribute type, the measurement unit and a\n",
            "   brief description.  The number of rings is the value to predict: either\n",
            "   as a continuous value or as a classification problem.\n",
            "\n",
            "\tName\t\tData Type\tMeas.\tDescription\n",
            "\t----\t\t---------\t-----\t-----------\n",
            "\tSex\t\tnominal\t\t\tM, F, and I (infant)\n",
            "\tLength\t\tcontinuous\tmm\tLongest shell measurement\n",
            "\tDiameter\tcontinuous\tmm\tperpendicular to length\n",
            "\tHeight\t\tcontinuous\tmm\twith meat in shell\n",
            "\tWhole weight\tcontinuous\tgrams\twhole abalone\n",
            "\tShucked weight\tcontinuous\tgrams\tweight of meat\n",
            "\tViscera weight\tcontinuous\tgrams\tgut weight (after bleeding)\n",
            "\tShell weight\tcontinuous\tgrams\tafter being dried\n",
            "\tRings\t\tinteger\t\t\t+1.5 gives the age in years\n",
            "\n",
            "   Statistics for numeric domains:\n",
            "\n",
            "\t\tLength\tDiam\tHeight\tWhole\tShucked\tViscera\tShell\tRings\n",
            "\tMin\t0.075\t0.055\t0.000\t0.002\t0.001\t0.001\t0.002\t    1\n",
            "\tMax\t0.815\t0.650\t1.130\t2.826\t1.488\t0.760\t1.005\t   29\n",
            "\tMean\t0.524\t0.408\t0.140\t0.829\t0.359\t0.181\t0.239\t9.934\n",
            "\tSD\t0.120\t0.099\t0.042\t0.490\t0.222\t0.110\t0.139\t3.224\n",
            "\tCorrel\t0.557\t0.575\t0.557\t0.540\t0.421\t0.504\t0.628\t  1.0\n",
            "\n",
            "\n",
            "8. Missing Attribute Values: None\n",
            "\n",
            "\n",
            "9. Class Distribution:\n",
            "\n",
            "\tClass\tExamples\n",
            "\t-----\t--------\n",
            "\t1\t1\n",
            "\t2\t1\n",
            "\t3\t15\n",
            "\t4\t57\n",
            "\t5\t115\n",
            "\t6\t259\n",
            "\t7\t391\n",
            "\t8\t568\n",
            "\t9\t689\n",
            "\t10\t634\n",
            "\t11\t487\n",
            "\t12\t267\n",
            "\t13\t203\n",
            "\t14\t126\n",
            "\t15\t103\n",
            "\t16\t67\n",
            "\t17\t58\n",
            "\t18\t42\n",
            "\t19\t32\n",
            "\t20\t26\n",
            "\t21\t14\n",
            "\t22\t6\n",
            "\t23\t9\n",
            "\t24\t2\n",
            "\t25\t1\n",
            "\t26\t1\n",
            "\t27\t2\n",
            "\t29\t1\n",
            "\t-----\t----\n",
            "\tTotal\t4177\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JB2jBkiF3j18",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 476
        },
        "outputId": "343f07f5-0d26-4807-ebfc-919241656240"
      },
      "source": [
        "# grab the text between the two tokens (7. Attribute information and 8. Attribute Values) to look at the names\n",
        "!cat abalone.names | sed -n \"/7. Attribute information:/,/8. Missing Attribute Values/p\" | head -n-1 | tail -n+2 > snip.txt\n",
        "!cat --number snip.txt"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "     1\t\n",
            "     2\t   Given is the attribute name, attribute type, the measurement unit and a\n",
            "     3\t   brief description.  The number of rings is the value to predict: either\n",
            "     4\t   as a continuous value or as a classification problem.\n",
            "     5\t\n",
            "     6\t\tName\t\tData Type\tMeas.\tDescription\n",
            "     7\t\t----\t\t---------\t-----\t-----------\n",
            "     8\t\tSex\t\tnominal\t\t\tM, F, and I (infant)\n",
            "     9\t\tLength\t\tcontinuous\tmm\tLongest shell measurement\n",
            "    10\t\tDiameter\tcontinuous\tmm\tperpendicular to length\n",
            "    11\t\tHeight\t\tcontinuous\tmm\twith meat in shell\n",
            "    12\t\tWhole weight\tcontinuous\tgrams\twhole abalone\n",
            "    13\t\tShucked weight\tcontinuous\tgrams\tweight of meat\n",
            "    14\t\tViscera weight\tcontinuous\tgrams\tgut weight (after bleeding)\n",
            "    15\t\tShell weight\tcontinuous\tgrams\tafter being dried\n",
            "    16\t\tRings\t\tinteger\t\t\t+1.5 gives the age in years\n",
            "    17\t\n",
            "    18\t   Statistics for numeric domains:\n",
            "    19\t\n",
            "    20\t\t\tLength\tDiam\tHeight\tWhole\tShucked\tViscera\tShell\tRings\n",
            "    21\t\tMin\t0.075\t0.055\t0.000\t0.002\t0.001\t0.001\t0.002\t    1\n",
            "    22\t\tMax\t0.815\t0.650\t1.130\t2.826\t1.488\t0.760\t1.005\t   29\n",
            "    23\t\tMean\t0.524\t0.408\t0.140\t0.829\t0.359\t0.181\t0.239\t9.934\n",
            "    24\t\tSD\t0.120\t0.099\t0.042\t0.490\t0.222\t0.110\t0.139\t3.224\n",
            "    25\t\tCorrel\t0.557\t0.575\t0.557\t0.540\t0.421\t0.504\t0.628\t  1.0\n",
            "    26\t\n",
            "    27\t\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5sDi0r0i6WjD",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 170
        },
        "outputId": "0ca8146b-f0df-4825-e37b-6ea4972b43c3"
      },
      "source": [
        "# want to grab first word of lines 8 through 16\n",
        "!sed -n '8,16p' snip.txt > snip2.txt # sed -n '16224,16482p;16483q' filename > newfile\n",
        "!cat snip2.txt # looks good"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\tSex\t\tnominal\t\t\tM, F, and I (infant)\n",
            "\tLength\t\tcontinuous\tmm\tLongest shell measurement\n",
            "\tDiameter\tcontinuous\tmm\tperpendicular to length\n",
            "\tHeight\t\tcontinuous\tmm\twith meat in shell\n",
            "\tWhole weight\tcontinuous\tgrams\twhole abalone\n",
            "\tShucked weight\tcontinuous\tgrams\tweight of meat\n",
            "\tViscera weight\tcontinuous\tgrams\tgut weight (after bleeding)\n",
            "\tShell weight\tcontinuous\tgrams\tafter being dried\n",
            "\tRings\t\tinteger\t\t\t+1.5 gives the age in years\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BMODCuGr6cXL",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 323
        },
        "outputId": "96046c37-1a31-4557-bc38-961218d5b337"
      },
      "source": [
        "# grab first word from each line\n",
        "!cat snip2.txt | awk '{print $1}' > features.txt\n",
        "import numpy as np\n",
        "features = np.loadtxt('features.txt', dtype=str)\n",
        "print( features )\n",
        "# have features and \n",
        "abalone_df = pd.read_csv('/content/abalone.data', names=features)\n",
        "print( abalone_df.head(15) )"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['Sex' 'Length' 'Diameter' 'Height' 'Whole' 'Shucked' 'Viscera' 'Shell'\n",
            " 'Rings']\n",
            "   Sex  Length  Diameter  Height   Whole  Shucked  Viscera  Shell  Rings\n",
            "0    M   0.455     0.365   0.095  0.5140   0.2245   0.1010  0.150     15\n",
            "1    M   0.350     0.265   0.090  0.2255   0.0995   0.0485  0.070      7\n",
            "2    F   0.530     0.420   0.135  0.6770   0.2565   0.1415  0.210      9\n",
            "3    M   0.440     0.365   0.125  0.5160   0.2155   0.1140  0.155     10\n",
            "4    I   0.330     0.255   0.080  0.2050   0.0895   0.0395  0.055      7\n",
            "5    I   0.425     0.300   0.095  0.3515   0.1410   0.0775  0.120      8\n",
            "6    F   0.530     0.415   0.150  0.7775   0.2370   0.1415  0.330     20\n",
            "7    F   0.545     0.425   0.125  0.7680   0.2940   0.1495  0.260     16\n",
            "8    M   0.475     0.370   0.125  0.5095   0.2165   0.1125  0.165      9\n",
            "9    F   0.550     0.440   0.150  0.8945   0.3145   0.1510  0.320     19\n",
            "10   F   0.525     0.380   0.140  0.6065   0.1940   0.1475  0.210     14\n",
            "11   M   0.430     0.350   0.110  0.4060   0.1675   0.0810  0.135     10\n",
            "12   M   0.490     0.380   0.135  0.5415   0.2175   0.0950  0.190     11\n",
            "13   F   0.535     0.405   0.145  0.6845   0.2725   0.1710  0.205     10\n",
            "14   F   0.470     0.355   0.100  0.4755   0.1675   0.0805  0.185     10\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fVJ3BdNqAIy0",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 374
        },
        "outputId": "95f7d8a9-ccd5-4a82-b890-45c851fb319c"
      },
      "source": [
        "print(abalone_df.describe())\n",
        "print(abalone_df.isna().sum()) #everything seems good in this one too"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "            Length     Diameter  ...        Shell        Rings\n",
            "count  4177.000000  4177.000000  ...  4177.000000  4177.000000\n",
            "mean      0.523992     0.407881  ...     0.238831     9.933684\n",
            "std       0.120093     0.099240  ...     0.139203     3.224169\n",
            "min       0.075000     0.055000  ...     0.001500     1.000000\n",
            "25%       0.450000     0.350000  ...     0.130000     8.000000\n",
            "50%       0.545000     0.425000  ...     0.234000     9.000000\n",
            "75%       0.615000     0.480000  ...     0.329000    11.000000\n",
            "max       0.815000     0.650000  ...     1.005000    29.000000\n",
            "\n",
            "[8 rows x 8 columns]\n",
            "Sex         0\n",
            "Length      0\n",
            "Diameter    0\n",
            "Height      0\n",
            "Whole       0\n",
            "Shucked     0\n",
            "Viscera     0\n",
            "Shell       0\n",
            "Rings       0\n",
            "dtype: int64\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i-0HO9tI8iDY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "?np.array_split\n",
        "?np.split"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "MZCxTwKuReV9"
      },
      "source": [
        "## Stretch Goals - Other types and sources of data\n",
        "\n",
        "Not all data comes in a nice single file - for example, image classification involves handling lots of image files. You still will probably want labels for them, so you may have tabular data in addition to the image blobs - and the images may be reduced in resolution and even fit in a regular csv as a bunch of numbers.\n",
        "\n",
        "If you're interested in natural language processing and analyzing text, that is another example where, while it can be put in a csv, you may end up loading much larger raw data and generating features that can then be thought of in a more standard tabular fashion.\n",
        "\n",
        "Overall you will in the course of learning data science deal with loading data in a variety of ways. Another common way to get data is from a database - most modern applications are backed by one or more databases, which you can query to get data to analyze. We'll cover this more in our data engineering unit.\n",
        "\n",
        "How does data get in the database? Most applications generate logs - text files with lots and lots of records of each use of the application. Databases are often populated based on these files, but in some situations you may directly analyze log files. The usual way to do this is with command line (Unix) tools - command lines are intimidating, so don't expect to learn them all at once, but depending on your interests it can be useful to practice.\n",
        "\n",
        "One last major source of data is APIs: https://github.com/toddmotto/public-apis\n",
        "\n",
        "API stands for Application Programming Interface, and while originally meant e.g. the way an application interfaced with the GUI or other aspects of an operating system, now it largely refers to online services that let you query and retrieve data. You can essentially think of most of them as \"somebody else's database\" - you have (usually limited) access.\n",
        "\n",
        "*Stretch goal* - research one of the above extended forms of data/data loading. See if you can get a basic example working in a notebook. Image, text, or (public) APIs are probably more tractable - databases are interesting, but there aren't many publicly accessible and they require a great deal of setup."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "f4QP6--JBXNK",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}