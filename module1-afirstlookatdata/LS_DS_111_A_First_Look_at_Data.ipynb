{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "LS DS 111 - A First Look at Data.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/trista-paul/DS-Sprint-01-Dealing-With-Data/blob/master/module1-afirstlookatdata/LS_DS_111_A_First_Look_at_Data.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "metadata": {
        "id": "Okfr_uhwhS1X",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Lambda School Data Science - A First Look at Data\n",
        "\n"
      ]
    },
    {
      "metadata": {
        "id": "9dtJETFRhnOG",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Lecture - let's explore Python DS libraries and examples!\n",
        "\n",
        "The Python Data Science ecosystem is huge. You've seen some of the big pieces - pandas, scikit-learn, matplotlib. What parts do you want to see more of?"
      ]
    },
    {
      "metadata": {
        "id": "WiBkgmPJhmhE",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "04beae39-69e0-4520-c2f1-31e3aa237ac1"
      },
      "cell_type": "code",
      "source": [
        "# TODO - we'll be doing this live, taking requests\n",
        "# and reproducing what it is to look up and learn things\n",
        "1+1\n",
        "\n",
        "%matplotlib inline\n",
        "import pandas as pd \n",
        "titles = [] # list of news titles\n",
        "categories = [] # list of news categories\n",
        "labels = [] # list of different categories (without repetitions)\n",
        "nlabels = 4 # number of different categories\n",
        "lnews = [] # list of dictionaries with two fields: one for the news and \n",
        "            # the other for its category\n",
        "  \n",
        "!wget http://archive.ics.uci.edu/ml/datasets/News+Aggregator\n",
        "!unzip NewsAggregatorDataset.zip\n",
        "\n",
        "news_df = pd.read_table(\"NewsAggregatorDataset.zip\")\n",
        "news_df_head()\n",
        "\n",
        "def import_data():\n",
        "    global titles, labels, categories\n",
        "    # importing news aggregator data via Pandas (Python Data Analysis Library)\n",
        "    news = pd.read_csv(\"uci-news-aggregator.csv\")\n",
        "    # function 'head' shows the first 5 items in a column (or\n",
        "    # the first 5 rows in the DataFrame)\n",
        "    print(news.head())\n",
        "    categories = news['CATEGORY']\n",
        "    titles = news['TITLE']\n",
        "    labels = sorted(list(set(categories)))\n",
        "%time import_data()"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "2"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 1
        }
      ]
    },
    {
      "metadata": {
        "id": "lOqaPds9huME",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Assignment - now it's your turn\n",
        "\n",
        "Pick at least one Python DS library, and using documentation/examples reproduce in this notebook something cool. It's OK if you don't fully understand it or get it 100% working, but do put in effort and look things up."
      ]
    },
    {
      "metadata": {
        "id": "TGUS79cOhPWj",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 118
        },
        "outputId": "174a4b62-d36e-4991-ee3a-f1603e5135d2"
      },
      "cell_type": "code",
      "source": [
        "# TODO - your code here\n",
        "# Use what we did live in lecture as an example\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "df = pd.read_table(\"https://datasets.imdbws.com/title.ratings.tsv.gz\")\n",
        "#print(df.head(5))\n",
        "df2 = pd.read_table(\"https://datasets.imdbws.com/title.crew.tsv.gz\")\n",
        "df2 = df2.drop(columns='writers')\n",
        "#print(df2.head(5))\n",
        "imdb = pd.merge(df,df2)\n",
        "imdb = imdb[imdb['numVotes']>= 500]\n",
        "imdb = imdb.sort_values(by='averageRating')\n",
        "print(imdb.head(5))"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "           tconst  averageRating  numVotes                      directors\n",
            "607329  tt2215191            1.0       527                             \\N\n",
            "567989  tt1885205            1.0      2083                      nm1726456\n",
            "621199  tt2337458            1.0       573  nm4863798,nm3136987,nm3117618\n",
            "572860  tt1934806            1.1      1144                      nm4337659\n",
            "182424  tt0329794            1.1       969                      nm0344761\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "BT9gdS7viJZa",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Assignment questions\n",
        "\n",
        "After you've worked on some code, answer the following questions in this text block:\n",
        "\n",
        "1.  Describe in a paragraph of text what you did and why, as if you were writing an email to somebody interested but nontechnical.\n",
        "\n",
        "**Using IMDB's datasets for films and movies, I found the worst directors by average rating (for movies with more than 500 votes).**\n",
        "\n",
        "\n",
        "2.  What was the most challenging part of what you did?\n",
        "\n",
        "**Because IMDB's dataset is so large categories that would typically be on one spreadsheet were broken apart. **\n",
        "\n",
        "\n",
        "3.  What was the most interesting thing you learned?\n",
        "\n",
        "\n",
        "\n",
        "4.  What area would you like to explore with more time?\n",
        "The dataset uses an id in place of names ... if I worked on this again I'd like to figure out a way to fetch the names from id\n",
        "\n",
        "\n"
      ]
    },
    {
      "metadata": {
        "id": "_XXg2crAipwP",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Stretch goals and resources\n",
        "\n",
        "Following are *optional* things for you to take a look at. Focus on the above assignment first, and make sure to commit and push your changes to GitHub (and since this is the first assignment of the sprint, open a PR as well).\n",
        "\n",
        "- [pandas documentation](https://pandas.pydata.org/pandas-docs/stable/)\n",
        "- [scikit-learn documentation](http://scikit-learn.org/stable/documentation.html)\n",
        "- [matplotlib documentation](https://matplotlib.org/contents.html)\n",
        "- [Awesome Data Science](https://github.com/bulutyazilim/awesome-datascience) - a list of many types of DS resources\n",
        "\n",
        "Stretch goals:\n",
        "\n",
        "- Find and read blogs, walkthroughs, and other examples of people working through cool things with data science - and share with your classmates!\n",
        "- Write a blog post (Medium is a popular place to publish) introducing yourself as somebody learning data science, and talking about what you've learned already and what you're excited to learn more about"
      ]
    }
  ]
}