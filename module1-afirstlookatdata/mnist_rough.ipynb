{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "mnist_rough.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/quinn-dougherty/DS-Sprint-01-Dealing-With-Data/blob/master/module1-afirstlookatdata/mnist_rough.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "metadata": {
        "id": "fdcSzlths25T",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "## walkthru of this https://medium.com/deep-learning-turkey/google-colab-free-gpu-tutorial-e113627b9f5d \n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "kpCSLjlJtA-r",
        "colab_type": "code",
        "outputId": "98d81d9c-332d-425b-f4f6-c74fa8c9ca39",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive/', force_remount=True)"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive/\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "NNvYTT7WtyOy",
        "colab_type": "code",
        "outputId": "ccfccf05-239a-4fe7-f76d-e004a431a1be",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "!ls \"/content/drive/My Drive/app\"\n",
        "# !ls \"/content/drive/My Drive/\""
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "mnist_cnn.py\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "9HAev0t7t_za",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "!pip install -q keras"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "8Mcg6qgzv_d5",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from __future__ import print_function\n",
        "import keras\n",
        "from keras.datasets import mnist\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Dropout, Flatten\n",
        "from keras.layers import Conv2D, MaxPooling2D\n",
        "from keras import backend as K\n",
        "\n",
        "batch_size = 128\n",
        "num_classes = 10\n",
        "epochs = 12"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "PqTbHHcfwN4B",
        "colab_type": "code",
        "outputId": "f7f96eb3-c052-4c30-aca9-1aec9bd5ff40",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 751
        }
      },
      "cell_type": "code",
      "source": [
        "!python3 \"/content/drive/My Drive/app/mnist_cnn.py\""
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n",
            "x_train shape: (60000, 28, 28, 1)\n",
            "60000 train samples\n",
            "10000 test samples\n",
            "Train on 60000 samples, validate on 10000 samples\n",
            "Epoch 1/12\n",
            "2018-11-05 21:58:20.569440: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:964] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2018-11-05 21:58:20.569942: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1432] Found device 0 with properties: \n",
            "name: Tesla K80 major: 3 minor: 7 memoryClockRate(GHz): 0.8235\n",
            "pciBusID: 0000:00:04.0\n",
            "totalMemory: 11.17GiB freeMemory: 11.00GiB\n",
            "2018-11-05 21:58:20.569985: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1511] Adding visible gpu devices: 0\n",
            "2018-11-05 21:58:20.993703: I tensorflow/core/common_runtime/gpu/gpu_device.cc:982] Device interconnect StreamExecutor with strength 1 edge matrix:\n",
            "2018-11-05 21:58:20.993777: I tensorflow/core/common_runtime/gpu/gpu_device.cc:988]      0 \n",
            "2018-11-05 21:58:20.993804: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1001] 0:   N \n",
            "2018-11-05 21:58:20.994088: W tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:42] Overriding allow_growth setting because the TF_FORCE_GPU_ALLOW_GROWTH environment variable is set. Original config value was 0.\n",
            "2018-11-05 21:58:20.994161: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1115] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 10657 MB memory) -> physical GPU (device: 0, name: Tesla K80, pci bus id: 0000:00:04.0, compute capability: 3.7)\n",
            "60000/60000 [==============================] - 11s 177us/step - loss: 0.2662 - acc: 0.9182 - val_loss: 0.0592 - val_acc: 0.9813\n",
            "Epoch 2/12\n",
            "60000/60000 [==============================] - 9s 144us/step - loss: 0.0883 - acc: 0.9739 - val_loss: 0.0437 - val_acc: 0.9858\n",
            "Epoch 3/12\n",
            "60000/60000 [==============================] - 9s 144us/step - loss: 0.0648 - acc: 0.9811 - val_loss: 0.0350 - val_acc: 0.9876\n",
            "Epoch 4/12\n",
            "60000/60000 [==============================] - 9s 144us/step - loss: 0.0532 - acc: 0.9842 - val_loss: 0.0311 - val_acc: 0.9888\n",
            "Epoch 5/12\n",
            "60000/60000 [==============================] - 9s 144us/step - loss: 0.0458 - acc: 0.9866 - val_loss: 0.0294 - val_acc: 0.9901\n",
            "Epoch 6/12\n",
            "60000/60000 [==============================] - 9s 144us/step - loss: 0.0402 - acc: 0.9878 - val_loss: 0.0275 - val_acc: 0.9910\n",
            "Epoch 7/12\n",
            "60000/60000 [==============================] - 9s 144us/step - loss: 0.0361 - acc: 0.9894 - val_loss: 0.0268 - val_acc: 0.9907\n",
            "Epoch 8/12\n",
            "60000/60000 [==============================] - 9s 144us/step - loss: 0.0326 - acc: 0.9899 - val_loss: 0.0260 - val_acc: 0.9920\n",
            "Epoch 9/12\n",
            "60000/60000 [==============================] - 9s 143us/step - loss: 0.0309 - acc: 0.9902 - val_loss: 0.0259 - val_acc: 0.9916\n",
            "Epoch 10/12\n",
            "60000/60000 [==============================] - 9s 144us/step - loss: 0.0276 - acc: 0.9914 - val_loss: 0.0268 - val_acc: 0.9917\n",
            "Epoch 11/12\n",
            "60000/60000 [==============================] - 9s 144us/step - loss: 0.0261 - acc: 0.9920 - val_loss: 0.0272 - val_acc: 0.9910\n",
            "Epoch 12/12\n",
            "60000/60000 [==============================] - 9s 144us/step - loss: 0.0246 - acc: 0.9919 - val_loss: 0.0256 - val_acc: 0.9926\n",
            "Test loss: 0.02558496432144275\n",
            "Test accuracy: 0.9926\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "f13XpodIxVXO",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "## we learned MNIST with 0.99 accuracy by running a convolutional neural net on GPU! "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "sIgpKn6zyRDw",
        "colab_type": "code",
        "outputId": "efe3ee6e-a427-41ea-f663-c4ac72dbe635",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "# test if GPU is working\n",
        "\n",
        "import tensorflow as tf\n",
        "tf.test.gpu_device_name()\n",
        "#yep, working. \n",
        "\n",
        "# we're on a Tesla K80"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'/device:GPU:0'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 29
        }
      ]
    },
    {
      "metadata": {
        "id": "NlgG34Vmyeov",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 289
        },
        "outputId": "d97f4b8f-b1cf-45de-f1b2-48e3f68b1d3e"
      },
      "cell_type": "code",
      "source": [
        "## let's see if we can open up tensorboard\n",
        "\n",
        "# You can change the directory name\n",
        "LOG_DIR = 'tb_logs'\n",
        "\n",
        "!wget https://bin.equinox.io/c/4VmDzA7iaHb/ngrok-stable-linux-amd64.zip\n",
        "!unzip ngrok-stable-linux-amd64.zip\n",
        "\n",
        "import os\n",
        "if not os.path.exists(LOG_DIR):\n",
        "  os.makedirs(LOG_DIR)\n",
        "  \n",
        "get_ipython().system_raw(\n",
        "    'tensorboard --logdir {} --host 0.0.0.0 --port 6006 &'\n",
        "    .format(LOG_DIR))\n",
        "\n",
        "get_ipython().system_raw('./ngrok http 6006 &')\n",
        "\n",
        "!curl -s http://localhost:4040/api/tunnels | python3 -c \\\n",
        "    \"import sys, json; print(json.load(sys.stdin)['tunnels'][0]['public_url'])\""
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2018-11-05 22:00:33--  https://bin.equinox.io/c/4VmDzA7iaHb/ngrok-stable-linux-amd64.zip\n",
            "Resolving bin.equinox.io (bin.equinox.io)... 52.22.213.157, 52.22.236.254, 52.4.95.48, ...\n",
            "Connecting to bin.equinox.io (bin.equinox.io)|52.22.213.157|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 5363700 (5.1M) [application/octet-stream]\n",
            "Saving to: ‘ngrok-stable-linux-amd64.zip’\n",
            "\n",
            "ngrok-stable-linux- 100%[===================>]   5.11M  3.42MB/s    in 1.5s    \n",
            "\n",
            "2018-11-05 22:00:35 (3.42 MB/s) - ‘ngrok-stable-linux-amd64.zip’ saved [5363700/5363700]\n",
            "\n",
            "Archive:  ngrok-stable-linux-amd64.zip\n",
            "  inflating: ngrok                   \n",
            "Traceback (most recent call last):\n",
            "  File \"<string>\", line 1, in <module>\n",
            "IndexError: list index out of range\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "HZllntxD5Dlh",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}