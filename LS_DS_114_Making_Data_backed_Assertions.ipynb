{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "LS DS 114 - Making Data-backed Assertions.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [
        "9dtJETFRhnOG"
      ],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ed-chin-git/DS-Sprint-01-Dealing-With-Data/blob/master/LS_DS_114_Making_Data_backed_Assertions.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "metadata": {
        "id": "Okfr_uhwhS1X",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Lambda School Data Science - Making Data-backed Assertions\n",
        "\n",
        "This is, for many, the main point of data science - to create and support reasoned arguments based on evidence. It's not a topic to master in a day, but it is worth some focused time thinking about and structuring your approach to it."
      ]
    },
    {
      "metadata": {
        "id": "9dtJETFRhnOG",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Lecture - generating a confounding variable\n",
        "\n",
        "The prewatch material told a story about a hypothetical health condition where both the drug usage and overall health outcome were related to gender - thus making gender a confounding variable, obfuscating the possible relationship between the drug and the outcome.\n",
        "\n",
        "Let's use Python to generate data that actually behaves in this fashion!"
      ]
    },
    {
      "metadata": {
        "id": "WiBkgmPJhmhE",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import random\n",
        "dir(random)  # Reminding ourselves what we can do here"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Ks5qFtpnq-q5",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Let's think of another scenario:\n",
        "# We work for a company that sells accessories for mobile phones.\n",
        "# They have an ecommerce site, and we are supposed to analyze logs\n",
        "# to determine what sort of usage is related to purchases, and thus guide\n",
        "# website development to encourage higher conversion.\n",
        "\n",
        "# The hypothesis - users who spend longer on the site tend\n",
        "# to spend more. Seems reasonable, no?\n",
        "\n",
        "# But there's a confounding variable! If they're on a phone, they:\n",
        "# a) Spend less time on the site, but\n",
        "# b) Are more likely to be interested in the actual products!\n",
        "\n",
        "# Let's use namedtuple to represent our data\n",
        "\n",
        "from collections import namedtuple\n",
        "# purchased and mobile are bools, time_on_site in seconds\n",
        "User = namedtuple('User', ['purchased','time_on_site', 'mobile'])\n",
        "\n",
        "example_user = User(False, 12, False)\n",
        "print(example_user)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "lfPiHNG_sefL",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# And now let's generate 1000 example users\n",
        "# 750 mobile, 250 not (i.e. desktop)\n",
        "# A desktop user has a base conversion likelihood of 10%\n",
        "# And it goes up by 1% for each 15 seconds they spend on the site\n",
        "# And they spend anywhere from 10 seconds to 10 minutes on the site (uniform)\n",
        "# Mobile users spend on average half as much time on the site as desktop\n",
        "# But have twice as much base likelihood of buying something\n",
        "\n",
        "users = []\n",
        "\n",
        "for _ in range(250):\n",
        "  # Desktop users\n",
        "  time_on_site = random.uniform(10, 600)\n",
        "  purchased = random.random() < 0.1 + (time_on_site / 1500)\n",
        "  users.append(User(purchased, time_on_site, False))\n",
        "  \n",
        "for _ in range(750):\n",
        "  # Mobile users\n",
        "  time_on_site = random.uniform(5, 300)\n",
        "  purchased = random.random() < 0.2 + (time_on_site / 1500)\n",
        "  users.append(User(purchased, time_on_site, True))\n",
        "  \n",
        "random.shuffle(users)\n",
        "print(users[:10])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "9gDYb5qGuRzy",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Let's put this in a dataframe so we can look at it more easily\n",
        "import pandas as pd\n",
        "user_data = pd.DataFrame(users)\n",
        "user_data.head()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "sr6IJv77ulVl",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Let's use crosstabulation to try to see what's going on\n",
        "pd.crosstab(user_data['purchased'], user_data['time_on_site'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "hvAv6J3EwA9s",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# OK, that's not quite what we want\n",
        "# Time is continuous! We need to put it in discrete buckets\n",
        "# Pandas calls these bins, and pandas.cut helps make them\n",
        "\n",
        "time_bins = pd.cut(user_data['time_on_site'], 5)  # 5 equal-sized bins\n",
        "pd.crosstab(user_data['purchased'], time_bins)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "pjcXnJw0wfaj",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# We can make this a bit clearer by normalizing (getting %)\n",
        "pd.crosstab(user_data['purchased'], time_bins, normalize='columns')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "C3GzvDxlvZMa",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# That seems counter to our hypothesis\n",
        "# More time on the site seems to have fewer purchases\n",
        "\n",
        "# But we know why, since we generated the data!\n",
        "# Let's look at mobile and purchased\n",
        "pd.crosstab(user_data['purchased'], user_data['mobile'], normalize='columns')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "frre7YF0aYWo",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# More on binning\n",
        "pd.cut(user_data['time_on_site'], 5)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "6QQieUkmayAf",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "help(pd.cut)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "KQb-wU60xCum",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Yep, mobile users are more likely to buy things\n",
        "# But we're still not seeing the *whole* story until we look at all 3 at once\n",
        "\n",
        "# Live/stretch goal - how can we do that?\n",
        "pd.crosstab([user_data['purchased'], time_bins], user_data['mobile'],\n",
        "            normalize='columns')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "s7h0zj7pkYZV",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "help(user_data.plot.bar)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "6O0ac41kkykR",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "user_data.plot.bar()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "SZPa27dFlE8x",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# So we have a working barchart method\n",
        "# Does it just expand our crosstab?\n",
        "ct = pd.crosstab([user_data['purchased'], time_bins], user_data['mobile'],\n",
        "                 normalize='columns')\n",
        "ct"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "FrbCGVJslxU9",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "dir(ct)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "q_Jk05m-l8pK",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "ct.plot(kind='bar', stacked=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "pS4SsAySmJ4J",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Courtesy of A\n",
        "pd.crosstab(time_bins, [user_data['purchased'], user_data['mobile']],\n",
        "            normalize='columns').plot(kind = 'bar', stacked = False);"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "2Sn5TxLXqMFp",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Starting point for mobile/desktop stacked barcharts\n",
        "# Probably want to redo with fewer time-bins\n",
        "pd.crosstab(user_data['mobile'], [user_data['purchased'], time_bins],\n",
        "            normalize='columns').plot(kind = 'bar', stacked = True);"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "7Z54lKEnrA04",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "'scatter' in dir(ct.plot)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "a3y2lP-XrHct",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "grouped_data = user_data['mobile'].groupby(user_data['purchased'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "3q4ClQGOrWa4",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "dir(grouped_data)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "450B-o9urk6a",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# TODO continue exploring grouped_data, grouped_data.plot, etc."
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "nOwQwvEsmXkw",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "[x for x in dir(ct) if 'add' in x]  # Courtesy of Ryan Herr"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "pF3by6aEm5T-",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "ct_props = dir(ct)\n",
        "'add' in ct_props"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "APyKMGrMokh8",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "ct.boxplot()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "63g2hLrTeBgH",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "!apt install r-base"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "kTAxEHXFeOxA",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "!R --version"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "HVQsGW3GeMn-",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "!pip install rpy2"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "m9klpr8JglcV",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Download the data\n",
        "data_url = 'https://github.com/lockedata/datasauRus/raw/master/data/simpsons_paradox.rda'\n",
        "\n",
        "!wget $data_url\n",
        "!ls"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "t4VNA6Aghapr",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "!pip install tzlocal"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "YoYUaqfWdzjb",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Trying to load R data in Python\n",
        "# https://itsalocke.com/datasaurus/reference/simpsons_paradox\n",
        "# https://stackoverflow.com/questions/40160149/reading-rda-file-in-python-as-a-pandas-data-frame#40161783\n",
        "\n",
        "import rpy2.robjects as robjects\n",
        "from rpy2.robjects import default_converter\n",
        "from rpy2.robjects import pandas2ri\n",
        "from rpy2.robjects.conversion import localconverter\n",
        "pandas2ri.activate()\n",
        "\n",
        "# load your file\n",
        "robjects.r['load']('simpsons_paradox.rda')\n",
        "\n",
        "# use the default conversion rules to which the pandas conversion\n",
        "# is added\n",
        "with localconverter(default_converter + pandas2ri.converter) as cv:\n",
        "    df = robjects.r[\"data\"]\n",
        "\n",
        "matrix = robjects.r['data']\n",
        "\n",
        "matrix"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "rJznsoSkiISQ",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "thing = df()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "rDWmxMmdiLpd",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "for item in thing.items():\n",
        "  print(item)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "lOqaPds9huME",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Assignment - what's going on here?\n",
        "\n",
        "Consider the data in `persons.csv` (already prepared for you, in the repo for the week). It has four columns - a unique id, followed by age (in years), weight (in lbs), and exercise time (in minutes/week) of 1200 (hypothetical) people.\n",
        "\n",
        "Try to figure out which variables are possibly related to each other, and which may be confounding relationships."
      ]
    },
    {
      "metadata": {
        "id": "TGUS79cOhPWj",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 374
        },
        "outputId": "3cb5c699-3929-45fa-d09f-238ce93dc314"
      },
      "cell_type": "code",
      "source": [
        "# TODO - your code here\n",
        "# Use what we did live in lecture as an example\n",
        "\n",
        "# HINT - you can find the raw URL on GitHub and potentially use that\n",
        "# https://raw.githubusercontent.com/ed-chin-git/DS-Sprint-01-Dealing-With-Data/master/module4-databackedassertions/persons.csv\n",
        "import pandas as pd\n",
        "\n",
        "data_url='https://raw.githubusercontent.com/ed-chin-git/DS-Sprint-01-Dealing-With-Data/master/module4-databackedassertions/persons.csv'\n",
        "df=pd.read_csv(data_url)\n",
        "print(df.shape)\n",
        "print(df.describe())\n",
        "df.head()"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(1200, 4)\n",
            "        Unnamed: 0          age       weight  exercise_time\n",
            "count  1200.000000  1200.000000  1200.000000    1200.000000\n",
            "mean    599.500000    48.396667   153.540833     134.910833\n",
            "std     346.554469    18.166802    35.132182      85.548895\n",
            "min       0.000000    18.000000   100.000000       0.000000\n",
            "25%     299.750000    33.000000   125.000000      65.000000\n",
            "50%     599.500000    48.000000   149.000000     122.000000\n",
            "75%     899.250000    64.000000   180.250000     206.000000\n",
            "max    1199.000000    80.000000   246.000000     300.000000\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Unnamed: 0</th>\n",
              "      <th>age</th>\n",
              "      <th>weight</th>\n",
              "      <th>exercise_time</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>44</td>\n",
              "      <td>118</td>\n",
              "      <td>192</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>41</td>\n",
              "      <td>161</td>\n",
              "      <td>35</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>46</td>\n",
              "      <td>128</td>\n",
              "      <td>220</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>39</td>\n",
              "      <td>216</td>\n",
              "      <td>57</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>28</td>\n",
              "      <td>116</td>\n",
              "      <td>182</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   Unnamed: 0  age  weight  exercise_time\n",
              "0           0   44     118            192\n",
              "1           1   41     161             35\n",
              "2           2   46     128            220\n",
              "3           3   39     216             57\n",
              "4           4   28     116            182"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "metadata": {
        "id": "BT9gdS7viJZa",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "\n",
        "### Assignment questions\n",
        "\n",
        "After you've worked on some code, answer the following questions in this text block:\n",
        "\n",
        "1.  What are the variable types in the data?\n",
        "2.  What are the relationships between the variables?\n",
        "3.  Which relationships are \"real\", and which spurious?\n"
      ]
    },
    {
      "metadata": {
        "id": "_XXg2crAipwP",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Stretch goals and resources\n",
        "\n",
        "Following are *optional* things for you to take a look at. Focus on the above assignment first, and make sure to commit and push your changes to GitHub.\n",
        "\n",
        "- [Spurious Correlations](http://tylervigen.com/spurious-correlations)\n",
        "- [NIH on controlling for confounding variables](https://www.ncbi.nlm.nih.gov/pmc/articles/PMC4017459/)\n",
        "\n",
        "Stretch goals:\n",
        "\n",
        "- Produce your own plot inspierd by the Spurious Correlation visualizations (and consider writing a blog post about it - both the content and how you made it)\n",
        "- Pick one of the techniques that NIH highlights for confounding variables - we'll be going into many of them later, but see if you can find which Python modules may help (hint - check scikit-learn)"
      ]
    }
  ]
}